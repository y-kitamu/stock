{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import datetime\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative dataのうち、値下がりが大きいものをピックアップ\n",
    "negative_data_dir = stock.DATA_DIR / \"train/neg\"\n",
    "negative_data_list = sorted(negative_data_dir.glob(\"*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(\"code(\\d+)_date(\\d+)_rate\\d+\\.png\")\n",
    "target = []\n",
    "\n",
    "for neg_path in tqdm(negative_data_list):\n",
    "    res = regex.search(neg_path.name)\n",
    "    code, date = res.group(1), datetime.datetime.strptime(res.group(2), \"%Y%m%d\").date()\n",
    "    df = stock.kabutan.read_data_csv(code, start_date=date + datetime.timedelta(days=1), end_date=date + datetime.timedelta(days=28))\n",
    "    start = df[\"open\"][0]\n",
    "    minimum = df[\"low\"].min()\n",
    "    if minimum < start * 0.8:\n",
    "        target.append(neg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_dir = stock.DATA_DIR / \"train/super_neg\"\n",
    "dst_dir.mkdir(exist_ok=True)\n",
    "# for src in target:\n",
    "#     shutil.copy(src, dst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_image(code, date, before_days, output_dir=None, width=256, height=256):\n",
    "    if output_dir is not None:\n",
    "        output_path = Path(output_dir) / \"code{}_date{}.jpg\".format(code, date.strftime(\"%Y%m%d\"))\n",
    "        if output_path.exists():\n",
    "            return output_path\n",
    "    df = stock.kabutan.read_data_csv(code, end_date=date)[-before_days:]\n",
    "    base = df[\"close\"][-1]\n",
    "    #fig = make_subplots(rows=1, cols=1)\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True,\"r\":-0.06}]])\n",
    "\n",
    "    x = [i for i in range(len(df))]\n",
    "    # 売買高\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x, y=df[\"volume\"] / df[\"volume\"][-1], \n",
    "            name=\"volume\", \n",
    "            line_color=\"rgba(0, 0, 255, 0.5)\"\n",
    "        ), \n",
    "        secondary_y=True\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Candlestick(\n",
    "            x=x,\n",
    "            open=df[\"open\"] / base,\n",
    "            high=df[\"high\"] / base,\n",
    "            low=df[\"low\"] / base,\n",
    "            close=df[\"close\"] / base,\n",
    "            name=\"candle\",\n",
    "        ),\n",
    "        secondary_y=False\n",
    "    )\n",
    "    # グラフの設定\n",
    "    fig.update_layout(\n",
    "        xaxis_rangeslider_visible=False,\n",
    "        showlegend=False,\n",
    "        xaxis=dict(visible=False),\n",
    "        yaxis=dict(visible=False), \n",
    "        yaxis_range=[0.7, 1.3],\n",
    "        width=width, height=height,\n",
    "        margin={'l': 0, 'r': 0, 't': 0, 'b': 0},\n",
    "    )\n",
    "    fig.layout.yaxis2.update(showticklabels=False, range=[0, 3])\n",
    "    if output_dir is not None:\n",
    "        #print(output_path)\n",
    "        fig.write_image(output_path, width=width, height=height, scale=1.0)\n",
    "        return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train (negative)データの準備\n",
    "regex = re.compile(\"code(\\d+)_date(\\d+)_rate\\d+\\.png\")\n",
    "train_neg_list = []\n",
    "output_dir = stock.DATA_DIR / \"train/20240727/neg\"\n",
    "for p in tqdm(dst_dir.glob(\"*.png\")):\n",
    "    res = regex.search(p.name)\n",
    "    code, date = res.group(1), datetime.datetime.strptime(res.group(2), \"%Y%m%d\").date()\n",
    "    train_neg_list.append([code, date])\n",
    "    #train_neg_list.append(write_image(code, date, 30, output_dir, width=196, height=196))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(positive)データの準備\n",
    "xml_path = stock.TRAIN_DATA_DIR / \"annotations_pos.xml\"\n",
    "tree = ET.parse(xml_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "target_positive = []\n",
    "images = [child for child in root if child.tag == \"image\"]\n",
    "for image in images:\n",
    "    for child in image:\n",
    "        if child.tag == \"tag\":\n",
    "            if child.attrib[\"label\"] == \"proper base\":\n",
    "                target_positive.append(image.attrib[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(\"code(\\d+)_date(\\d+)_rate\\d+\\.png\")\n",
    "train_pos_list = []\n",
    "output_dir = stock.DATA_DIR / \"train/20240727/pos\"\n",
    "for fname in tqdm(target_positive):\n",
    "    res = regex.search(fname)\n",
    "    code, date = res.group(1), datetime.datetime.strptime(res.group(2), \"%Y%m%d\").date()\n",
    "    train_pos_list.append([code, date])\n",
    "    #train_pos_list.append(write_image(code, date, 30, output_dir, width=196, height=196))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_schema(code, date, image_dir, schema_dir, label):\n",
    "    stem = \"code{}_date{}\".format(code, date.strftime(\"%Y%m%d\"))\n",
    "    image_path = image_dir / (stem + \".jpg\")\n",
    "    assert image_path.exists()\n",
    "    schema = stock.dl.dataloader.ImageDataloader.DataSchema(image_path=image_path, label=label)\n",
    "    schema_path = schema_dir / (stem + \".json\")\n",
    "    with open(schema_path, \"w\" , encoding=\"utf-8\") as f:\n",
    "        f.write(schema.model_dump_json(indent=4))\n",
    "    return schema_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = stock.PROJECT_ROOT / \"data/train/20240727/image\"\n",
    "schema_dir = stock.PROJECT_ROOT / \"data/train/20240727/schema\"\n",
    "for code, date in train_neg_list:\n",
    "    create_schema(code, date, image_dir, schema_dir, 0)\n",
    "for code, date in train_pos_list:\n",
    "    create_schema(code, date, image_dir, schema_dir, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid データの準備\n",
    "csv_path = stock.TRAIN_DATA_DIR / \"valid.csv\"\n",
    "valid_df = pl.read_csv(csv_path)\n",
    "max_hold_days = 10\n",
    "valid_schema_paths = []\n",
    "\n",
    "for i in range(len(valid_df)):\n",
    "    code, date = valid_df[\"code\"][i], datetime.datetime.strptime(valid_df[\"date\"][i], \"%Y-%m-%d\").date()\n",
    "    write_image(code, date, 30, image_dir, width=196, height=196)\n",
    "    df = stock.kabutan.read_data_csv(code, start_date=date, end_date=date + datetime.timedelta(days=28))\n",
    "    df = df.with_columns(\n",
    "        (pl.col(\"close\").rolling_max(window_size=max_hold_days).shift(-max_hold_days) / pl.col(\"open\").shift(-1)).alias(\"growing_rate\")\n",
    "    )\n",
    "    if df[\"growing_rate\"][0] is None:\n",
    "        continue\n",
    "    if df[\"growing_rate\"][0] > 1.4:\n",
    "        label = 1\n",
    "        valid_schema_paths.append(create_schema(code ,date, image_dir, schema_dir, label))\n",
    "    elif df[\"growing_rate\"][0] < 1.1:\n",
    "        label = 0\n",
    "        valid_schema_paths.append(create_schema(code ,date, image_dir, schema_dir, label))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_pos_list), len(train_neg_list), len(valid_schema_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_schemas = [schema_dir / \"code{}_date{}.json\".format(code, date.strftime(\"%Y%m%d\")) for code, date in train_pos_list]\n",
    "train_neg_schemas = [schema_dir / \"code{}_date{}.json\".format(code, date.strftime(\"%Y%m%d\")) for code, date in train_neg_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_dir = stock.PROJECT_ROOT / \"data/train/20240727/schema\"\n",
    "\n",
    "dataset = stock.dl.dataloader.ImageDataloader.Dataset(\n",
    "    train = [train_pos_schemas, train_neg_schemas],\n",
    "    valid=[valid_schema_paths]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = stock.TRAIN_DATA_DIR / \"20240727/dataset.json\"\n",
    "with open(dataset_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(dataset.model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = stock.TRAIN_DATA_DIR / \"20240727/dataset.json\"\n",
    "params = stock.dl.dataloader.ImageDataloader.Params(\n",
    "    batch_size=32, \n",
    "    dataset_json_path=dataset_path,\n",
    "    ratio_per_group=[1, 1,],\n",
    "    num_class=2\n",
    ")\n",
    "\n",
    "dataloader = stock.dl.dataloader.ImageDataloader(params, is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(self):\n",
    "    \"\"\" \"\"\"\n",
    "    ratio_per_group = [\n",
    "        rate / sum(self.params.ratio_per_group) for rate in self.params.ratio_per_group\n",
    "    ]\n",
    "    base_sample_per_group = [self.params.batch_size * rate for rate in ratio_per_group]\n",
    "    sample_per_group = [int(n) for n in base_sample_per_group]\n",
    "    residual = self.params.batch_size - sum(sample_per_group)\n",
    "    res_rate = [f - i for i, f in zip(sample_per_group, base_sample_per_group)]\n",
    "    if sum(res_rate) > 0.5:\n",
    "        res_rate = [r / sum(res_rate) for r in res_rate]\n",
    "        indices = np.random.choice([i for i in range(len(res_rate))], size=residual, p=res_rate)\n",
    "        for i in indices:\n",
    "            sample_per_group[i] += 1\n",
    "\n",
    "    sample = (\n",
    "        [\n",
    "            s\n",
    "            for num_sample, group in zip(sample_per_group, self.data_schema)\n",
    "            for s in random.sample(group, num_sample)\n",
    "        ]\n",
    "    )\n",
    "    image = (np.stack([cv2.imread(s.image_path) for s in sample]) / 255.0).astype(np.float32)\n",
    "    mat = np.identity(self.params.num_class)\n",
    "    label = np.stack([mat[s.label] for s in sample]).astype(np.float32)\n",
    "    return {\"input\": image, \"y_true\": label}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.sample(dataloader.data_schema[0], 16)\n",
    "len(\n",
    "        [\n",
    "            s\n",
    "            for num_sample, group in zip([16, 16], dataloader.data_schema)\n",
    "            for s in random.sample(group, num_sample)\n",
    "        ], \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res  = get_next(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"input\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(res[\"input\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
