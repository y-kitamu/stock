{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import datetime\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative dataのうち、値下がりが大きいものをピックアップ\n",
    "negative_data_dir = stock.DATA_DIR / \"train/neg\"\n",
    "negative_data_list = sorted(negative_data_dir.glob(\"*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(\"code(\\d+)_date(\\d+)_rate\\d+\\.png\")\n",
    "target = []\n",
    "\n",
    "for neg_path in tqdm(negative_data_list):\n",
    "    res = regex.search(neg_path.name)\n",
    "    code, date = res.group(1), datetime.datetime.strptime(res.group(2), \"%Y%m%d\").date()\n",
    "    df = stock.kabutan.read_data_csv(code, start_date=date + datetime.timedelta(days=1), end_date=date + datetime.timedelta(days=28))\n",
    "    start = df[\"open\"][0]\n",
    "    minimum = df[\"low\"].min()\n",
    "    if minimum < start * 0.8:\n",
    "        target.append(neg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_dir = stock.DATA_DIR / \"train/super_neg\"\n",
    "dst_dir.mkdir(exist_ok=True)\n",
    "# for src in target:\n",
    "#     shutil.copy(src, dst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_image(code, date, before_days, output_dir=None, width=256, height=256):\n",
    "    if output_dir is not None:\n",
    "        output_path = Path(output_dir) / \"code{}_date{}.jpg\".format(code, date.strftime(\"%Y%m%d\"))\n",
    "        if output_path.exists():\n",
    "            return output_path\n",
    "    df = stock.kabutan.read_data_csv(code, end_date=date)[-before_days:]\n",
    "    base = df[\"close\"][-1]\n",
    "    #fig = make_subplots(rows=1, cols=1)\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True,\"r\":-0.06}]])\n",
    "\n",
    "    x = [i for i in range(len(df))]\n",
    "    # 売買高\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x, y=df[\"volume\"] / df[\"volume\"][-1], \n",
    "            name=\"volume\", \n",
    "            line_color=\"rgba(0, 0, 255, 0.5)\"\n",
    "        ), \n",
    "        secondary_y=True\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Candlestick(\n",
    "            x=x,\n",
    "            open=df[\"open\"] / base,\n",
    "            high=df[\"high\"] / base,\n",
    "            low=df[\"low\"] / base,\n",
    "            close=df[\"close\"] / base,\n",
    "            name=\"candle\",\n",
    "        ),\n",
    "        secondary_y=False\n",
    "    )\n",
    "    # グラフの設定\n",
    "    fig.update_layout(\n",
    "        xaxis_rangeslider_visible=False,\n",
    "        showlegend=False,\n",
    "        xaxis=dict(visible=False),\n",
    "        yaxis=dict(visible=False), \n",
    "        yaxis_range=[0.7, 1.3],\n",
    "        width=width, height=height,\n",
    "        margin={'l': 0, 'r': 0, 't': 0, 'b': 0},\n",
    "    )\n",
    "    fig.layout.yaxis2.update(showticklabels=False, range=[0, 3])\n",
    "    if output_dir is not None:\n",
    "        #print(output_path)\n",
    "        fig.write_image(output_path, width=width, height=height, scale=1.0)\n",
    "        return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train (negative)データの準備\n",
    "regex = re.compile(\"code(\\d+)_date(\\d+)_rate\\d+\\.png\")\n",
    "train_neg_list = []\n",
    "output_dir = stock.DATA_DIR / \"train/20240727/neg\"\n",
    "for p in tqdm(dst_dir.glob(\"*.png\")):\n",
    "    res = regex.search(p.name)\n",
    "    code, date = res.group(1), datetime.datetime.strptime(res.group(2), \"%Y%m%d\").date()\n",
    "    train_neg_list.append(write_image(code, date, 30, output_dir, width=196, height=196))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(positive)データの準備\n",
    "xml_path = stock.TRAIN_DATA_DIR / \"annotations_pos.xml\"\n",
    "tree = ET.parse(xml_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "target_positive = []\n",
    "images = [child for child in root if child.tag == \"image\"]\n",
    "for image in images:\n",
    "    for child in image:\n",
    "        if child.tag == \"tag\":\n",
    "            if child.attrib[\"label\"] == \"proper base\":\n",
    "                target_positive.append(image.attrib[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(\"code(\\d+)_date(\\d+)_rate\\d+\\.png\")\n",
    "train_pos_list = []\n",
    "output_dir = stock.DATA_DIR / \"train/20240727/pos\"\n",
    "for fname in tqdm(target_positive):\n",
    "    res = regex.search(fname)\n",
    "    code, date = res.group(1), datetime.datetime.strptime(res.group(2), \"%Y%m%d\").date()\n",
    "    train_pos_list.append(write_image(code, date, 30, output_dir, width=196, height=196))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid データの準備\n",
    "csv_path = stock.TRAIN_DATA_DIR / \"valid.csv\"\n",
    "valid_df = pl.read_csv(csv_path)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    code, date = df[\"code\"][i], df[\"date\"][i]\n",
    "    write_image(code, date, 30, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_neg_list:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_dir = stock.PROJECT_ROOT / \"data/train/20240727/schema\"\n",
    "\n",
    "stock.dl.dataloader.ImageDataloader.Dataset(\n",
    "    train = [train_pos_list, train_neg_list]\n",
    "    valid=\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
