{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "import yfinance as yf\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import stock\n",
    "from stock.kabutan import get_code_list, read_data_csv, read_financial_csv\n",
    "from stock.kabutan.data import calc_estimated_capitalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minerviniの手法を日本株に取り入れてみる\n",
    "jumpups = stock.data.get_jumpups(\n",
    "    window_size=30, min_growing_rate=0.4, exclude_duplicate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_jumpups = sum([len(val) for val in jumpups.values()])\n",
    "print(\"Number of jumpups : {}\".format(total_jumpups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(code ,date):\n",
    "    df = read_data_csv(code, start_date=date - datetime.timedelta(days=30), end_date=date + datetime.timedelta(days=30))\n",
    "    idx = len(df.filter(pl.col(\"date\") <= date))\n",
    "    df = df.select( \n",
    "        pl.col(\"date\"),\n",
    "        pl.col(\"open\") / df[\"open\"][idx],\n",
    "        pl.col(\"high\") / df[\"open\"][idx],\n",
    "        pl.col(\"low\") / df[\"open\"][idx],\n",
    "        pl.col(\"close\") / df[\"open\"][idx],\n",
    "        pl.col(\"volume\"),\n",
    "    )\n",
    "    fig = stock.visualize.plot_chart(df, before_days=idx)\n",
    "    fig.update_layout(yaxis_range=[0.7, 1.5])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_watch_list_all() -> pl.DataFrame:\n",
    "    stacked: list[pl.DataFrame] = []\n",
    "    codes = get_code_list()\n",
    "    for code in tqdm(codes):\n",
    "        if code not in jumpups.keys(): # or len(jumpups[code]) < 2:\n",
    "            continue\n",
    "\n",
    "        start_date = jumpups[code][\"date\"][0]\n",
    "        capt = calc_estimated_capitalization(code)\n",
    "\n",
    "        if capt > 100000000000:  # 時価総額1000億円以上の場合はスキップ\n",
    "            continue\n",
    "\n",
    "        # df = calc_for_watch_list(code)\n",
    "        df = calc_for_watch_list(code, start_date=start_date + datetime.timedelta(30))\n",
    "        df = df.filter(pl.col(\"watch_list\"))#.with_columns(pl.lit(code).alias(\"code\")).select(pl.col(\"code\"), pl.col(\"date\"))\n",
    "        \n",
    "        # stacked += check_fundamentals(code, df)\n",
    "        stacked.append(df.select(pl.lit(code).alias(\"code\"), pl.col(\"date\")))\n",
    "    stacked_df = pl.concat(stacked)\n",
    "    return stacked_df\n",
    "    #return stacked\n",
    "\n",
    "\n",
    "def calc_for_watch_list(\n",
    "    code: str,\n",
    "    start_date: datetime.date | None = None,\n",
    "    end_date: datetime.date = datetime.date.today(),\n",
    "):\n",
    "    df = read_data_csv(code, start_date=start_date, end_date=end_date)\n",
    "    # 過去10日の値動きの大きさを計算\n",
    "    window_size = 10\n",
    "    avg_key = \"avg{}\".format(window_size)\n",
    "    stddev_key = \"stddev{}\".format(window_size)\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"close\").rolling_mean(window_size=window_size).alias(avg_key),\n",
    "        pl.col(\"close\").rolling_std(window_size=window_size).alias(stddev_key),\n",
    "    )\n",
    "\n",
    "    # ギャップアップしている\n",
    "    df = df.with_columns(\n",
    "        (pl.col(\"close\") > pl.col(avg_key) + pl.col(stddev_key)).alias(\"breakpoint\")\n",
    "    )\n",
    "\n",
    "    # 出来高が増加（急増）\n",
    "    window_size = 10\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"volume\").rolling_max(window_size=window_size).shift().alias(\"max_volume\")\n",
    "    )\n",
    "    df = df.with_columns(\n",
    "        (\n",
    "            (pl.col(\"volume\") > pl.col(\"max_volume\") * 2)\n",
    "            & (pl.col(\"volume\") * pl.col(\"close\") > 20000 * 100)\n",
    "            & (pl.col(\"volume\").rolling_max(window_size=30).shift() * 0.9 < pl.col(\"volume\"))\n",
    "        ).alias(\"volume_increase\")\n",
    "    )\n",
    "\n",
    "    # 移動平均線の計算 / 高値・安値からの距離\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"close\").rolling_mean(window_size=50).alias(\"ma50\"),\n",
    "        pl.col(\"close\").rolling_mean(window_size=150).alias(\"ma150\"),\n",
    "        pl.col(\"close\").rolling_mean(window_size=200).alias(\"ma200\"),\n",
    "        pl.col(\"close\").rolling_max(window_size=150).alias(\"max150\"),\n",
    "        pl.col(\"close\").rolling_min(window_size=150).alias(\"min150\"),\n",
    "    )\n",
    "    df = df.with_columns(\n",
    "        (((pl.col(\"ma150\").shift(1) - pl.col(\"ma150\")) > 0).cast(pl.Int32).rolling_sum(window_size=30) > 20).alias(\"ma_up\"),\n",
    "        ((pl.col(\"close\") > pl.col(\"min150\") * 1.3)).alias(\"high_low_dist\")\n",
    "    )\n",
    "\n",
    "    # watch listの条件判定\n",
    "    df = df.with_columns(\n",
    "        (\n",
    "          pl.col(\"breakpoint\")\n",
    "          & pl.col(\"volume_increase\")\n",
    "          & (pl.col(\"close\") > pl.col(\"ma150\"))\n",
    "        #   & pl.col(\"ma_up\")\n",
    "          # & pl.col(\"high_low_dist\")\n",
    "          & (pl.col(\"close\") > 50)\n",
    "      ).alias(\"watch_list\")\n",
    "    )\n",
    "\n",
    "\n",
    "    # 直前にwatch list候補になっている場合はwatch listから除く\n",
    "    df = df.with_columns(\n",
    "        (\n",
    "            (pl.col(\"watch_list\").cast(int).rolling_max(window_size=5).shift() == 0)\n",
    "            & pl.col(\"watch_list\")\n",
    "        ).alias(\"watch_list\")\n",
    "    )\n",
    "\n",
    "    # 決算発表前後の日はwatch_listから除く\n",
    "    # fdf = (\n",
    "    #     read_financial_csv(code)\n",
    "    #     .filter(pl.col(\"annoounce_date\") <= end_date)\n",
    "    #     .sort(pl.col(\"annoounce_date\"))\n",
    "    # )\n",
    "    # for announce_date in fdf[\"annoounce_date\"]:\n",
    "    #     df = df.with_columns(\n",
    "    #         (\n",
    "    #             pl.col(\"watch_list\")\n",
    "    #             & (\n",
    "    #                 ~pl.col(\"date\").is_between(\n",
    "    #                     announce_date - datetime.timedelta(7), announce_date + datetime.timedelta(7)\n",
    "    #                 )\n",
    "    #             )\n",
    "    #         ).alias(\"watch_list\")\n",
    "    #     )\n",
    "\n",
    "    return df\n",
    "\n",
    "def check_fundamentals(code: str, df: pl.DataFrame):\n",
    "    fdf = read_financial_csv(code)\n",
    "    \n",
    "    watch_list = []\n",
    "    # fundamentalsのチェック\n",
    "    for idx in range(len(df)):\n",
    "        ffdf = fdf.filter((pl.col(\"annoounce_date\") <= df[\"date\"][idx]) & (pl.col(\"duration\") == 3)).sort(pl.col(\"annoounce_date\"))\n",
    "        if len(ffdf) < 4 or df[\"date\"][idx] - ffdf[\"annoounce_date\"][-1] > datetime.timedelta(100):\n",
    "            #watch_list.append([code, df[\"date\"][idx]])\n",
    "            continue\n",
    "        if ffdf[\"operating_income\"][-1] is None or ffdf[\"total_revenue\"][-1] is None:\n",
    "            #watch_list.append([code, df[\"date\"][idx]])\n",
    "            continue\n",
    "        if ffdf[\"operating_income\"][-4] is None or ffdf[\"total_revenue\"][-4] is None:\n",
    "            #watch_list.append([code, df[\"date\"][idx]])\n",
    "            continue\n",
    "        if ffdf[\"operating_income\"][-1] > ffdf[\"operating_income\"][-4] * 1.2 and ffdf[\"total_revenue\"][-1] > ffdf[\"total_revenue\"][-4] * 1.2:\n",
    "            if ffdf[\"eps\"][-1] > 0 and df[\"close\"][idx] / (ffdf[\"eps\"][-1] * 4) > 30:\n",
    "                watch_list.append([code, df[\"date\"][idx]])\n",
    "                continue\n",
    "        \n",
    "\n",
    "    return watch_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watch_list = get_watch_list_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jumpupデータがwatchlistの中にどれくらい含まれているかチェック\n",
    "tp = 0\n",
    "tp_sum = 0\n",
    "jps = jumpups.copy()\n",
    "tp_list = []\n",
    "for idx in range(len(watch_list)):\n",
    "    #code, date = watch_list[idx][0], watch_list[idx][1]\n",
    "    code, date = watch_list[\"code\"][idx], watch_list[\"date\"][idx]\n",
    "    if code in jumpups:\n",
    "        #if (jumpups[code][\"date\"] == date).any():\n",
    "        if len(jumpups[code].filter(pl.col(\"date\").is_between(date - datetime.timedelta(days=10), date))) > 0:\n",
    "            tp += 1\n",
    "            tp_sum += len(jps[code].filter(pl.col(\"date\").is_between(\n",
    "                date - datetime.timedelta(days=10),\n",
    "                date + datetime.timedelta(days=10)\n",
    "            )))\n",
    "            jps[code] = jps[code].filter(pl.col(\"date\").is_between(\n",
    "                date - datetime.timedelta(days=10),\n",
    "                date + datetime.timedelta(days=10)\n",
    "            ).not_())\n",
    "            tp_list.append((code, date))\n",
    "\n",
    "print(\"Number of tp : {}, recall ={}, precision = {}\".format(\n",
    "    tp, tp_sum / total_jumpups, tp / len(watch_list)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_results = []\n",
    "for idx in tqdm(range(len(watch_list))):\n",
    "    #code, date = watch_list[idx][0], watch_list[idx][1]\n",
    "    code, date = watch_list[\"code\"][idx], watch_list[\"date\"][idx]\n",
    "    \n",
    "    cond = stock.simulation.CustomStopCondition(sell_rate=0.2)\n",
    "    simulation_results.append(stock.simulation.simulate.run(code, date, condition=cond))\n",
    "\n",
    "profits = [res.profit for res in simulation_results]\n",
    "print(\"Average profits : {}\".format(np.mean(profits)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_results = sorted(simulation_results, key=lambda x: x.profit, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"./tmp\")\n",
    "output_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sampleで適当に選んでみて検証\n",
    "sampled_df = watch_list.sample(100)\n",
    "for i in tqdm(range(len(sampled_df))):\n",
    "    code, date = sampled_df[\"code\"][i], sampled_df[\"date\"][i]\n",
    "    df = read_data_csv(code, start_date=date - datetime.timedelta(days=30), end_date=date)\n",
    "    df = df.select(\n",
    "        pl.col(\"date\"),\n",
    "        pl.col(\"open\") / df[\"close\"][-1],\n",
    "        pl.col(\"high\") / df[\"close\"][-1],\n",
    "        pl.col(\"low\") / df[\"close\"][-1],\n",
    "        pl.col(\"close\") / df[\"close\"][-1],\n",
    "        pl.col(\"volume\"),\n",
    "    )\n",
    "    fig = stock.visualize.plot_chart(\n",
    "        df#, before_days=idx\n",
    "    )\n",
    "\n",
    "    fig.update_layout(yaxis_range=[0.7, 1.5])\n",
    "    output_path = output_dir / \"{}_{}.jpg\".format(code, date)\n",
    "    fig.write_image(str(output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アノテーション結果を読み込んで検証\n",
    "xml_path = Path(\"./tmp/annotations.xml\")\n",
    "tree = ET.parse(xml_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "target_list = []\n",
    "non_target_list = []\n",
    "all_list = []\n",
    "for child in root:\n",
    "    if child.tag == \"image\":\n",
    "        filename = child.attrib[\"name\"]\n",
    "        all_list.append(filename)\n",
    "        for tag in child:\n",
    "            if tag.tag == \"tag\" and tag.attrib[\"label\"] == \"good\":\n",
    "                target_list.append(filename)\n",
    "                break\n",
    "        else:\n",
    "            non_target_list.append(filename)\n",
    "\n",
    "\n",
    "def simulation(filename_list):\n",
    "    simulation_results = []\n",
    "    regex = re.compile(r\"(\\d+)_(\\d+-\\d+-\\d+).jpg\")\n",
    "    for target in filename_list:\n",
    "        res = regex.search(target)\n",
    "        if res is None:\n",
    "            raise RuntimeError(\"Invalid filename : {}\".format(target))\n",
    "        code ,date = res.group(1), datetime.datetime.strptime(res.group(2), \"%Y-%m-%d\").date()\n",
    "\n",
    "        cond = stock.simulation.CustomStopCondition(sell_rate=0.2)\n",
    "        simulation_results.append(stock.simulation.simulate.run(code, date, condition=cond))\n",
    "    return simulation_results\n",
    "\n",
    "target_results = simulation(target_list)\n",
    "target_profits = [res.profit for res in target_results]\n",
    "print(\"Average profits : {}\".format(np.mean(target_profits)))\n",
    "\n",
    "non_target_results = simulation(non_target_list)\n",
    "non_target_profits = [res.profit for res in non_target_results]\n",
    "print(\"Average profits : {}\".format(np.mean(non_target_profits)))\n",
    "\n",
    "all_results = simulation(all_list)\n",
    "all_profits = [res.profit for res in all_results]\n",
    "print(\"Average profits : {}\".format(np.mean(all_profits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_list = sorted(all_list, key=lambda x: all_profits[all_list.index(x)])[::-1]\n",
    "sorted_results = simulation(sorted_list)\n",
    "sorted_profits = [res.profit for res in sorted_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "didx = 0\n",
    "\n",
    "filename = sorted_list[didx]\n",
    "profit = sorted_profits[didx]\n",
    "summary = sorted_results[didx].model_dump_json(indent=4)\n",
    "\n",
    "print(code, date, profit)\n",
    "print(summary)\n",
    "\n",
    "regex = re.compile(r\"(\\d+)_(\\d+-\\d+-\\d+).jpg\")\n",
    "res = regex.search(filename)\n",
    "code ,date = res.group(1), datetime.datetime.strptime(res.group(2), \"%Y-%m-%d\").date()\n",
    "plot(code, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jumpupデータがwatchlistの中にどれくらい含まれているかチェック\n",
    "tp = 0\n",
    "tp_sum = 0\n",
    "jps = jumpups.copy()\n",
    "tp_list = []\n",
    "for idx in range(len(watch_list)):\n",
    "    #code, date = watch_list[idx][0], watch_list[idx][1]\n",
    "    code, date = watch_list[\"code\"][idx], watch_list[\"date\"][idx]\n",
    "    if code in jumpups:\n",
    "        #if (jumpups[code][\"date\"] == date).any():\n",
    "        if len(jumpups[code].filter(pl.col(\"date\").is_between(date - datetime.timedelta(days=10), date))) > 0:\n",
    "            tp += 1\n",
    "            tp_sum += len(jps[code].filter(pl.col(\"date\").is_between(\n",
    "                date - datetime.timedelta(days=10),\n",
    "                date + datetime.timedelta(days=10)\n",
    "            )))\n",
    "            jps[code] = jps[code].filter(pl.col(\"date\").is_between(\n",
    "                date - datetime.timedelta(days=10),\n",
    "                date + datetime.timedelta(days=10)\n",
    "            ).not_())\n",
    "            tp_list.append((code, date))\n",
    "\n",
    "print(\"Number of tp : {}, recall ={}, precision = {}\".format(\n",
    "    tp, tp_sum / total_jumpups, tp / len(watch_list)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jumpupデータがwatchlistの中にどれくらい含まれているかチェック\n",
    "tp = 0\n",
    "tp_sum = 0\n",
    "jps = jumpups.copy()\n",
    "tp_list = []\n",
    "for idx in range(len(watch_list)):\n",
    "    code, date = watch_list[idx][0], watch_list[idx][1]\n",
    "    if code in jumpups:\n",
    "        if (jumpups[code][\"date\"] == date).any():\n",
    "            tp += 1\n",
    "            tp_sum += len(jps[code].filter(pl.col(\"date\").is_between(\n",
    "                date - datetime.timedelta(days=10),\n",
    "                date + datetime.timedelta(days=10)\n",
    "            )))\n",
    "            jps[code] = jps[code].filter(pl.col(\"date\").is_between(\n",
    "                date - datetime.timedelta(days=10),\n",
    "                date + datetime.timedelta(days=10)\n",
    "            ).not_())\n",
    "            tp_list.append((code, date))\n",
    "\n",
    "print(\"Number of tp : {}, recall ={}, precision = {}\".format(\n",
    "    tp, tp_sum / total_jumpups, tp / len(watch_list)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for idx in tqdm(range(len(watch_list))):\n",
    "    code, date = watch_list[\"code\"][idx], watch_list[\"date\"][idx]\n",
    "    cond = stock.simulation.CustomStopCondition(max_loss_rate=0.08, sell_rate=0.4, trailling_stop_rate=0.15)\n",
    "    results.append(stock.simulation.simulate.run(\n",
    "        code, start_date=date, condition=cond\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minerviniの売買をtrend templateに当てはまるかチェック\n",
    "# minerviniが実際に買った銘柄を探索する\n",
    "# https://wallstreettrader.substack.com/p/how-mark-minervini-won-us-investing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = [\n",
    "    [\"ANF\", datetime.date(2021, 1, 4)],\n",
    "    [\"GM\", datetime.date(2021, 1, 11)],\n",
    "    [\"STAA\", datetime.date(2021, 1, 12)],\n",
    "    [\"NNOX\", datetime.date(2021, 1, 20)],\n",
    "    [\"UAVS\", datetime.date(2021, 2, 9)],\n",
    "    [\"MP\", datetime.date(2021, 2, 9)],\n",
    "    [\"YETI\", datetime.date(2021, 4, 6)],\n",
    "    [\"ZIM\", datetime.date(2021, 4, 8)],\n",
    "    [\"BNTX\", datetime.date(2021, 6, 2)],\n",
    "    [\"AAPL\", datetime.date(2021, 6, 17)],\n",
    "    [\"MRNA\", datetime.date(2021, 6, 25)],\n",
    "    [\"SKY\", datetime.date(2021, 6, 30)],\n",
    "    [\"NUE\", datetime.date(2021, 8, 9)],\n",
    "    [\"PAG\", datetime.date(2021, 9, 1)],\n",
    "    [\"TSLA\", datetime.date(2021, 9, 24)],\n",
    "    [\"OLN\", datetime.date(2021, 10, 11)],\n",
    "    [\"ASYS\", datetime.date(2021, 10, 26)],\n",
    "    [\"UPST\", datetime.date(2021, 10, 12)],\n",
    "]\n",
    "\n",
    "target_list_short = [\n",
    "    [\"NVDA\", datetime.date(2021, 12, 3)],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq_df = stock.util.get_history_data(\"^IXIC\")\n",
    "sp500_df = stock.util.get_history_data(\"^GSPC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rss = []\n",
    "for code, buy_date in target_list:\n",
    "    df = stock.util.get_history_data(code)\n",
    "    df = df.filter(pl.col(\"date\").is_between(buy_date - datetime.timedelta(days=365), buy_date + datetime.timedelta(days=365)))\n",
    "    #ndf = nasdaq_df.filter(pl.col(\"date\").is_between(buy_date - datetime.timedelta(days=365), buy_date + datetime.timedelta(days=365)))\n",
    "    ndf = sp500_df.filter(pl.col(\"date\").is_between(buy_date - datetime.timedelta(days=365), buy_date + datetime.timedelta(days=365)))\n",
    "\n",
    "    duration = 260\n",
    "    prev_df = df.filter(pl.col(\"date\").is_between(buy_date- datetime.timedelta(days=duration), buy_date))\n",
    "    prev_nasdaq_df = ndf.filter(pl.col(\"date\").is_between(buy_date - datetime.timedelta(days=duration), buy_date))\n",
    "\n",
    "    rs = stock.algorithm.relative_strength.relative_strength(\n",
    "        prev_df[\"close\"].to_numpy(), \n",
    "        prev_nasdaq_df[\"close\"].to_numpy(),\n",
    "        num_division=duration // 10,\n",
    "        division_factor=1.02\n",
    "    )\n",
    "    rss.append(rs)\n",
    "    if rss[-1] < 100:\n",
    "        print(code, buy_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative strengthの計算\n",
    "def relative_strength_df(target_df, ref_df, offset=20, num_division=3, division_factor=1.02):\n",
    "    window_size = num_division * offset\n",
    "    # 不要な日付を削除\n",
    "    dates = target_df[\"date\"].to_list()\n",
    "    ref_dates = ref_df.filter(pl.col(\"date\") >= dates[0])[\"date\"].to_list()\n",
    "    excludes = [d for d in ref_dates if d not in dates]\n",
    "    ref_df = ref_df.filter(pl.col(\"date\").is_in(excludes).not_())\n",
    "\n",
    "    ref_df = ref_df.with_columns(\n",
    "        (pl.col(\"close\") / pl.col(\"close\").shift(offset)).alias(\"strength\")\n",
    "    )\n",
    "\n",
    "    # dfの用意\n",
    "    target_df = target_df.filter(pl.col(\"date\").is_between(ref_df[\"date\"][0], ref_df[\"date\"][-1]))\n",
    "    target_df = target_df.with_columns(\n",
    "        (pl.col(\"close\")  / pl.col(\"close\").shift(offset)).alias(\"strength\"),\n",
    "        pl.Series(name=\"ref_strength\", values=ref_df.filter(pl.col(\"date\").is_between(df[\"date\"][0], df[\"date\"][-1]))[\"strength\"]),\n",
    "    )\n",
    "    # 重みの計算\n",
    "    weights = np.array([division_factor**i for i in range(num_division)], dtype=float)\n",
    "    weights /= np.linalg.norm(weights, ord=1)\n",
    "    weights = [weights[i // offset] if (i % offset) == 0 else 0 for i in range(window_size)][::-1]\n",
    "    # rs算出\n",
    "    target_df = target_df.filter(\n",
    "        pl.col(\"strength\").is_not_null(), \n",
    "        pl.col(\"ref_strength\").is_not_null()\n",
    "    ).with_columns(\n",
    "        (pl.col(\"strength\") / pl.col(\"ref_strength\")).rolling_sum(window_size, weights=weights).alias(\"rs\")\n",
    "    )\n",
    "    return target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df ,date, before=30, after=30, yrange=[0.7, 1.4]):\n",
    "    df = df.filter(pl.col(\"date\").is_between(date - datetime.timedelta(days=before), date + datetime.timedelta(days=after)))\n",
    "    idx = len(df.filter(pl.col(\"date\") <= date))\n",
    "    if idx == len(df):\n",
    "        idx -= 1\n",
    "    df = df.select( \n",
    "        pl.col(\"date\"),\n",
    "        pl.col(\"open\") / df[\"open\"][idx],\n",
    "        pl.col(\"high\") / df[\"open\"][idx],\n",
    "        pl.col(\"low\") / df[\"open\"][idx],\n",
    "        pl.col(\"close\") / df[\"open\"][idx],\n",
    "        pl.col(\"volume\"),\n",
    "    )\n",
    "    fig = stock.visualize.plot_chart(df, before_days=idx)\n",
    "    fig.update_layout(yaxis_range=yrange)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trend templateに当てはまるかチェック\n",
    "nikkei_df = read_data_csv(\"0000\", exclude_none=False)\n",
    "\n",
    "def check_trendtemplate(df):\n",
    "    df =  df.with_columns(\n",
    "        pl.col(\"close\").rolling_mean(window_size=50, min_periods=10).alias(\"ma50\"),\n",
    "        pl.col(\"close\").rolling_mean(window_size=150, min_periods=10).alias(\"ma150\"),\n",
    "        pl.col(\"close\").rolling_mean(window_size=200, min_periods=10).alias(\"ma200\"),\n",
    "        pl.col(\"close\").rolling_max(window_size=260, min_periods=10).alias(\"max260\"),\n",
    "        pl.col(\"close\").rolling_min(window_size=260, min_periods=10).alias(\"min260\"),\n",
    "    )\n",
    "    \n",
    "    df = df.with_columns(\n",
    "        # 移動平均線が順番に並んでいる\n",
    "        ((pl.col(\"close\") > pl.col(\"ma50\")) & (pl.col(\"ma50\") + 1e-5 > pl.col(\"ma150\")) & (pl.col(\"ma150\") + 1e-5 > pl.col(\"ma200\"))).alias(\"ma_order\"),\n",
    "        # 移動平均線が上向き\n",
    "        *[((pl.col(ma) > pl.col(ma).shift()).cast(pl.Int32).rolling_sum(window_size=5) >= 4).alias(f\"{ma}_uptrend\") for ma in [\"ma50\", \"ma150\", \"ma200\"]],\n",
    "        # 高値・安値からの距離が適切\n",
    "        ((pl.col(\"close\") > pl.col(\"high\") * 0.75) & (pl.col(\"close\") > pl.col(\"min260\") * 1.3)).alias(\"high_low_dist\"),\n",
    "    )\n",
    "    # relative strengthの計算\n",
    "    df = relative_strength_df(df, nikkei_df, offset=20, num_division=10, division_factor=1.02)\n",
    "    \n",
    "    df = df.with_columns(\n",
    "        (pl.col(\"ma_order\") & pl.col(\"ma50_uptrend\") & pl.col(\"ma150_uptrend\") & pl.col(\"ma200_uptrend\") & pl.col(\"high_low_dist\") & (pl.col(\"rs\") > 0.98)).alias(\"trend_template\")\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trend templateを日本株に適用\n",
    "code_list = get_code_list()\n",
    "trend_rate = []\n",
    "for code in tqdm(code_list):\n",
    "    df = read_data_csv(code)\n",
    "    if len(df) < 100:\n",
    "        continue\n",
    "    df = check_trendtemplate(df)\n",
    "    trend_rate.append(len(df.filter(pl.col(\"trend_template\"))) / len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "growing_rates = []\n",
    "\n",
    "for code in tqdm(code_list):\n",
    "    df = read_data_csv(code)\n",
    "    if len(df) < 100:\n",
    "        continue\n",
    "\n",
    "    df = check_trendtemplate(df)\n",
    "    df = df.with_columns(\n",
    "        (pl.col(\"close\").shift(-30) / pl.col(\"close\")).alias(\"growing_rate\")\n",
    "    ).filter(\n",
    "        pl.col(\"growing_rate\").is_not_null()\n",
    "    )\n",
    "    if len(df.filter(pl.col(\"trend_template\"))) > 10 and len(df.filter(pl.col(\"trend_template\").not_())) > 10:\n",
    "        growing_rates.append([\n",
    "            df.filter(pl.col(\"trend_template\"))[\"growing_rate\"].mean(), \n",
    "            df.filter(pl.col(\"trend_template\").not_())[\"growing_rate\"].mean()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minerviniの手法を日本株に取り入れてみる\n",
    "jumpups = stock.data.get_jumpups(\n",
    "    window_size=30, min_growing_rate=0.4, exclude_duplicate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for code in jumpups.keys():\n",
    "    target_dates = jumpups[code][\"date\"].to_list()\n",
    "    for d in target_dates:\n",
    "        rows.append([code, d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上昇銘柄の特徴を調査\n",
    "index = 161\n",
    "code, target_date = rows[index]\n",
    "df = read_data_csv(code)\n",
    "\n",
    "print(code, target_date)\n",
    "plot(df, target_date, before=150, after=50, yrange=[0.7, 1.4])\n",
    "#plot(df, target_date, before=150, after=10, yrange=[0.8, 1.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "output_path = Path(\"./tmp/jumpups.csv\")\n",
    "with open(output_path, \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"code\", \"date\"])\n",
    "    writer.writerows(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "\n",
    "from polars import DataFrame\n",
    "\n",
    "\n",
    "class StopCondition(stock.simulation.CustomStopCondition):\n",
    "\n",
    "    def set_start(self, src_df: DataFrame, start_date: date) -> float:\n",
    "        res = super().set_start(src_df, start_date)\n",
    "        if res != -1:\n",
    "            df = src_df.filter(pl.col(\"date\") <= start_date).sort(pl.col(\"date\"))\n",
    "            # 寄り付きで値上がりしすぎの場合は買わない\n",
    "            limit_range = stock.algorithm.market.get_limit_range(df[\"close\"][-1])\n",
    "            if abs(df[\"open\"][1] - df[\"close\"][0]) > limit_range * 0.3:\n",
    "                self.reset_results()\n",
    "                return -1\n",
    "            # loss cutを定率か抵抗線で設定\n",
    "            self.loss_cut_price = max(df[-15:][\"low\"].min(), self.loss_cut_price)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "code_list = get_code_list()\n",
    "\n",
    "window_size = 15\n",
    "value_range = 0.05\n",
    "low_vola_rates = []\n",
    "bp_dfs = []\n",
    "for code in tqdm(code_list):\n",
    "    df = read_data_csv(code)\n",
    "    df = df.with_columns(\n",
    "        (((pl.col(\"high\").rolling_max(window_size=window_size) - pl.col(\"low\").rolling_min(window_size=window_size)) / pl.col(\"close\")) < value_range).alias(\"low_volatility\")\n",
    "    )\n",
    "    df = df.with_columns(\n",
    "        (\n",
    "            pl.col(\"low_volatility\").shift() \n",
    "            & pl.col(\"low_volatility\").not_() \n",
    "            & (pl.col(\"close\") > pl.col(\"high\").rolling_max(window_size=window_size).shift())\n",
    "            & (pl.col(\"volume\") > 10000)\n",
    "            & (pl.col(\"volume\") < 100000)\n",
    "            & (pl.col(\"volume\") > pl.col(\"volume\").rolling_min(window_size=5).shift() * 2)\n",
    "            & (pl.col(\"volume\") > pl.col(\"volume\").rolling_max(window_size=5).shift() * 0.8)\n",
    "            & (pl.col(\"volume\") < pl.col(\"volume\").rolling_max(window_size=20).shift() * 0.8)\n",
    "         ).alias(\"breakpoint\")\n",
    "    )\n",
    "    df = df.with_columns(\n",
    "        (pl.col(\"high\").rolling_max(window_size=30).shift(-30) / pl.col(\"open\").shift(-1)).alias(\"max30\"),\n",
    "        (pl.col(\"low\").rolling_min(window_size=30).shift(-30) / pl.col(\"open\").shift(-1)).alias(\"min30\"),\n",
    "    )\n",
    "    if len(df.filter(pl.col(\"breakpoint\"))) > 0:\n",
    "        low_vola_rates.append(len(df.filter(pl.col(\"breakpoint\"))) / len(df))\n",
    "        bp_dfs.append(df.filter(pl.col(\"breakpoint\")).with_columns(pl.lit(code).alias(\"code\")))\n",
    "    \n",
    "bp_df = pl.concat(bp_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in tqdm(range(len(bp_df))):\n",
    "    code, date = bp_df[\"code\"][i], bp_df[\"date\"][i]\n",
    "    res = stock.simulation.run(code, date, condition=StopCondition(sell_rate=0.2, max_loss_rate=0.08, max_days=14))\n",
    "    if res.duration.days == 0 and abs(res.profit) < 1e-5:\n",
    "        continue\n",
    "    results.append(res)\n",
    "\n",
    "profits = [res.profit for res in results]\n",
    "days = [res.duration.days for res in results]\n",
    "dates = [res.buying_date for res in results]\n",
    "cand_per_day = len(results) / ((max(dates) - min(dates)).days / 7 * 5)\n",
    "print(\"Average profits : {}, Average days : {}\".format(np.mean(profits), np.mean(days)))\n",
    "print(\"Yearly estimated profits : {}\".format(52 * 5 / np.mean(days) * np.mean(profits)))\n",
    "print(\"Candidates per day : {:.3f}, per average duration : {:.3f}\".format(cand_per_day, cand_per_day * np.mean(days)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in tqdm(range(len(bp_df))):\n",
    "    code, date = bp_df[\"code\"][i], bp_df[\"date\"][i]\n",
    "    res = stock.simulation.run(code, date, condition=StopCondition(sell_rate=0.2, max_loss_rate=0.08))\n",
    "    if res.duration.days == 0 and abs(res.profit) < 1e-5:\n",
    "        continue\n",
    "    results.append(res)\n",
    "\n",
    "profits = [res.profit for res in results]\n",
    "days = [res.duration.days for res in results]\n",
    "dates = [res.buying_date for res in results]\n",
    "cand_per_day = len(results) / ((max(dates) - min(dates)).days / 7 * 5)\n",
    "print(\"Average profits : {}, Average days : {}\".format(np.mean(profits), np.mean(days)))\n",
    "print(\"Yearly estimated profits : {}\".format(52 * 5 / np.mean(days) * np.mean(profits)))\n",
    "print(\"Candidates per day : {:.3f}, per average duration : {:.3f}\".format(cand_per_day, cand_per_day * np.mean(days)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(days, profits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sorted(results, key=lambda x: x.profit, reverse=True)\n",
    "\n",
    "idx = -7\n",
    "code, date = results[idx].code, results[idx].buying_date\n",
    "print(code, date, results[idx].profit)\n",
    "df = read_data_csv(code)\n",
    "plot(df, date, before=150, after=0, yrange=[0.7, 1.4])\n",
    "plot(df, date, before=150, after=50, yrange=[0.7, 1.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
