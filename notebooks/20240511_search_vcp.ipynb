{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# volatitlityが低下している日を探す\n",
    "import datetime \n",
    "\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "import time\n",
    "\n",
    "import stock\n",
    "\n",
    "daily_csv_dir = stock.PROJECT_ROOT / \"data/daily\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"4107\"\n",
    "#start_date = datetime.date(year=2024, month=1, day=1)\n",
    "#end_date = datetime.date.today() # datetime.date(year=2024, month=2, day=21)\n",
    "end_date = datetime.date(year=2024, month=3, day=10)\n",
    "start_date = end_date - datetime.timedelta(days=365)\n",
    "csv_path = daily_csv_dir / f\"{code}.csv\"\n",
    "df = stock.kabutan.read_data_csv(csv_path)\n",
    "extremal_df = stock.algorithm.extremal.calc_extremal(df, is_exact=False, start_date=start_date, end_date=end_date)\n",
    "print(check_vcp_pattern(end_date, df, debug=True), check_fundamentals(code, end_date, debug=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extremal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polars_map_batch(func):\n",
    "    \"\"\"\n",
    "    ```python\n",
    "    @polars_map_batch\n",
    "    def test(dates, days=30):\n",
    "        return dates - datetime.timedelta(days=days)\n",
    "\n",
    "    df = df.with_columns(pl.col(\"date\").map_batches(test).alias(\"test\"))\n",
    "    ```\n",
    "    \"\"\"\n",
    "    def _map_batch(pl_obj, *args, **kwargs):\n",
    "        res = [func(data, *args, **kwargs) for data in pl_obj]\n",
    "        return pl.Series(res)\n",
    "\n",
    "    return _map_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_date = end_date\n",
    "df = df.with_columns(\n",
    "    avg200=pl.col(\"close\").rolling_mean(window_size=200),\n",
    "    diff200=pl.col(\"close\").rolling_mean(window_size=200).diff()\n",
    ")\n",
    "start_date = target_date - datetime.timedelta(days=365)\n",
    "\n",
    "# trend templateのチェック\n",
    "# 200日移動平均線が上向き\n",
    "df = df.filter(pl.col(\"diff200\").is_not_null()).filter(pl.col(\"date\") <= target_date)\n",
    "    \n",
    "# # 出来高が少なすぎない\n",
    "# if df[\"volume\"] < 3000:\n",
    "#     return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VCPのパターンを自動的に探してくる\n",
    "def check_vcp_pattern(target_date: datetime.date, df: pl.DataFrame, debug: bool = False):\n",
    "    df = df.with_columns(\n",
    "        avg200=pl.col(\"close\").rolling_mean(window_size=200),\n",
    "        diff200=pl.col(\"close\").rolling_mean(window_size=200).diff()\n",
    "    )\n",
    "    start_date = target_date - datetime.timedelta(days=365)\n",
    "\n",
    "    # trend templateのチェック\n",
    "    # 200日移動平均線が上向き\n",
    "    df = df.filter(pl.col(\"diff200\").is_not_null()).filter(pl.col(\"date\") <= target_date)\n",
    "    if len(df) > 0:\n",
    "        if df[\"diff200\"][-1] < 0:\n",
    "            not debug or print(\"avg200 is downward.\")\n",
    "            return False\n",
    "        if df[\"avg200\"][-1] > df[\"close\"][-1]:\n",
    "            not debug or print(\"lower than avg200\")\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "    # 出来高が少なすぎない\n",
    "    if df[\"volume\"][-30:].mean() < 3000:\n",
    "        not debug or print(\"Too few volume.\", df[\"volume\"][-30:].mean())\n",
    "        return False\n",
    "\n",
    "    extremal_df = stock.algorithm.extremal.calc_extremal(\n",
    "        df, window_size=4, is_exact=False, use_future=False, start_date=start_date, end_date=target_date)\n",
    "    if len(extremal_df) == 0:\n",
    "        not debug or print(\"No extremal\")\n",
    "        return False\n",
    "    \n",
    "    # 高値が2回以上\n",
    "    high_extremal_df = extremal_df.filter(pl.col(\"high\") == pl.col(\"rolling_high\"))\n",
    "    if len(high_extremal_df) < 2:\n",
    "        not debug or print(\"Too few high extremal\")\n",
    "        return False\n",
    "    \n",
    "    highest_idx = high_extremal_df[\"high\"][:-1].arg_max()\n",
    "    # baseの形成開始から3週間以上経過していることをチェック\n",
    "    if high_extremal_df[\"date\"][highest_idx] + datetime.timedelta(21) > target_date:  \n",
    "        not debug or print(\"Too few days from starting base\")\n",
    "        return False\n",
    "\n",
    "    highest = high_extremal_df[\"high\"][highest_idx]\n",
    "    thresh_high = highest * 0.90\n",
    "    thresh_low = highest * 0.65\n",
    "    i_cnt_high = 0\n",
    "\n",
    "    # 現在値が高値付近\n",
    "    if highest * 0.95 > df[\"close\"][-1]:\n",
    "        not debug or print(\"lower than highest\")\n",
    "        return False\n",
    "    \n",
    "    # relative strengthが高い\n",
    "    if df[\"rs\"][-1] < 1.0:\n",
    "        not debug or print(\"rs < 0\")\n",
    "        return False\n",
    "\n",
    "    if high_extremal_df[\"high\"][-1] > highest * 1.02:\n",
    "        not debug or print(\"higher than base top\")\n",
    "        return False\n",
    "\n",
    "    for i in range(len(extremal_df)):\n",
    "        row = extremal_df[-1 - i]\n",
    "        if row[\"high\"][0] == row[\"rolling_high\"][0]:\n",
    "            if row[\"high\"][0] > thresh_high:\n",
    "                i_cnt_high += 1\n",
    "            \n",
    "        if row[\"low\"][0] == row[\"rolling_low\"][0]:\n",
    "            if row[\"low\"][0] < thresh_low:\n",
    "                break\n",
    "\n",
    "    return i_cnt_high > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def get_market_capitalization(\n",
    "    code: str, base_url: str = \"https://kabutan.jp/stock/?code={}\"\n",
    ") -> int:\n",
    "    res = requests.get(base_url.format(code))\n",
    "    soup = BeautifulSoup(res.text, features=\"lxml\")\n",
    "\n",
    "    market_cap = 0\n",
    "    market_cap_div = soup.find(\"div\", {\"id\": \"stockinfo_i3\"})\n",
    "    if market_cap_div is None:\n",
    "        return market_cap\n",
    "    market_cap_table = market_cap_div.find(\"table\")\n",
    "    if market_cap_table is None:\n",
    "        return market_cap\n",
    "    for table_row in market_cap_table.find_all(\"tr\"):\n",
    "        th = table_row.find(\"th\")\n",
    "        if th is not None and th.text == \"時価総額\":\n",
    "            td = table_row.find(\"td\")\n",
    "            market_cap = stock.util.convert_to_number(td.text)\n",
    "            break\n",
    "\n",
    "    return market_cap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_fundamentals(code, current_date = datetime.date.today(), debug: bool = False):\n",
    "    csv_path = stock.PROJECT_ROOT / \"data/financial\" / f\"{code}.csv\"\n",
    "    df = stock.kabutan.read_financial_csv(csv_path)\n",
    "    df = df.filter(pl.col(\"annoounce_date\") <= current_date)\n",
    "    \n",
    "    # 実績がプラス\n",
    "    yearly_df = df.filter((pl.col(\"duration\") == 12) &  (pl.col(\"is_prediction\") == False)).sort(pl.col(\"annoounce_date\"))\n",
    "    latest_year = yearly_df[-1]\n",
    "    net_income = latest_year[\"net_income\"][0]\n",
    "    operating_income = latest_year[\"operating_income\"][0]\n",
    "    if net_income is None or net_income < 0 or operating_income is None or operating_income < 0:\n",
    "        not debug or print(\"net_income < 0 or operating_income < 0\")\n",
    "        return False\n",
    "\n",
    "    # 予測がプラス\n",
    "    pred_df = df.filter((pl.col(\"duration\") == 12) &  (pl.col(\"is_prediction\") == True)).sort(pl.col(\"annoounce_date\"))\n",
    "    latest_pred = pred_df[-1]\n",
    "    pred_net_income = latest_pred[\"net_income\"][0]\n",
    "    pred_operating_income = latest_pred[\"operating_income\"][0]\n",
    "    if pred_net_income is None or pred_net_income < 0 or pred_operating_income is None or pred_operating_income < 0:\n",
    "        not debug or print(\"pred net income < 0 or pred operating_income < 0\")\n",
    "        return False\n",
    "    \n",
    "    # 業績予測がプラス\n",
    "    # if pred_net_income < net_income  or pred_operating_income < operating_income:\n",
    "    #     not debug or print(\"pred < actual\")\n",
    "    #     return False\n",
    "    \n",
    "    # 時価総額が適切な大きさ\n",
    "    market_capitalization = get_market_capitalization(code)\n",
    "    if market_capitalization < 100 or 5000 < market_capitalization:\n",
    "        not debug or print(\"invalid market capitalization\")\n",
    "        return False\n",
    "    time.sleep(0.05)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_watch_list(current_date = datetime.date.today()):\n",
    "    code_csv_path = stock.PROJECT_ROOT / \"data/data_j.csv\"\n",
    "    code_df = pl.read_csv(code_csv_path)\n",
    "    code_df = code_df.filter(pl.col(\"市場・商品区分\").str.contains(\"内国株式\"))\n",
    "\n",
    "    watch_list = []\n",
    "    for i in tqdm.tqdm(range(len(code_df))):\n",
    "        code = code_df[\"コード\"][i]\n",
    "        csv_path = daily_csv_dir / f\"{code}.csv\"\n",
    "        df = stock.kabutan.read_data_csv(csv_path)\n",
    "        if check_vcp_pattern(current_date, df) and check_fundamentals(code, current_date):\n",
    "            watch_list.append(code)\n",
    "    return watch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watch_list_cur = get_watch_list(datetime.date.today())\n",
    "#watch_list_prev = get_watch_list(datetime.date.today() - datetime.timedelta(days=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(watch_list_cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(watch_list_cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watch_list_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(\n",
    "    pl.col(\"date\").map_batches(lambda data : polars_map_batch(check_vcp_pattern)(data, df)).alias(\"is_vcp\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Config.set_tbl_rows(-1)\n",
    "print(df.filter(pl.col(\"is_vcp\")))\n",
    "pl.Config.set_tbl_rows(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"3696\"\n",
    "csv_path = daily_csv_dir / f\"{code}.csv\"\n",
    "df = stock.kabutan.read_data_csv(csv_path)\n",
    "# チャート上の極値を計算\n",
    "df = df.with_columns(\n",
    "    high_extremal_cand=((pl.col(\"high\").diff() > 0) & (pl.col(\"high\").diff().shift(-1) < 0)),\n",
    "    low_extremal_cand=((pl.col(\"low\").diff() < 0) & (pl.col(\"low\").diff().shift(-1) > 0)),\n",
    "    rolling_high=pl.col(\"high\").rolling_max(window_size=7, center=True).fill_null(strategy=\"forward\").fill_null(strategy=\"backward\"),\n",
    "    rolling_low=pl.col(\"low\").rolling_min(window_size=7, center=True).fill_null(strategy=\"forward\").fill_null(strategy=\"backward\"),\n",
    ")\n",
    "extremal_df = df.filter(\n",
    "    (pl.col(\"high_extremal_cand\") & (pl.col(\"rolling_high\") == pl.col(\"high\"))) |\n",
    "    (pl.col(\"low_extremal_cand\") & (pl.col(\"rolling_low\") == pl.col(\"low\")))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extremal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extremal_df = extremal_df.with_columns(\n",
    "    high_extremal=(pl.col(\"high_extremal_cand\") & (pl.col(\"rolling_high\") == pl.col(\"high\"))),\n",
    "    low_extremal=(pl.col(\"low_extremal_cand\") & (pl.col(\"rolling_low\") == pl.col(\"low\"))),\n",
    ")\n",
    "\n",
    "rows = [extremal_df[0]]\n",
    "for i in range(1, len(extremal_df)):\n",
    "    row = extremal_df[i]\n",
    "    if (rows[-1][\"high_extremal\"][0] and rows[-1][\"low_extremal\"][0]) or (\n",
    "        row[\"high_extremal\"][0] and row[\"low_extremal\"][0]\n",
    "    ):\n",
    "        rows.append(row)  # 一日のうちに極大と極小が現れる場合は追加\n",
    "    elif (rows[-1][\"high_extremal\"][0] and row[\"low_extremal\"][0]) or (\n",
    "        rows[-1][\"low_extremal\"][0] and row[\"high_extremal\"][0]\n",
    "    ):\n",
    "        rows.append(row)\n",
    "    else:\n",
    "        # 極大(極小)が連続して並んでいる場合は、高い(低い)方を残す\n",
    "        if rows[-1][\"high_extremal\"][0] and rows[-1][\"high\"][0] < row[\"high\"][0]:\n",
    "            rows[-1] = row\n",
    "        elif rows[-1][\"low_extremal\"][0] and rows[-1][\"low\"][0] > row[\"low\"][0]:\n",
    "            rows[-1] = row\n",
    "extremal_df = pl.concat(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Config.set_tbl_rows(-1)\n",
    "print(extremal_df\n",
    "      .filter(pl.col(\"date\").is_between(datetime.date(year=2023, month=11, day=29), datetime.date(year=2024, month=1, day=15)))\n",
    "      .select(pl.col(\"date\"), pl.col(\"high\"), pl.col(\"high_extremal_cand\"), pl.col(\"rolling_high\"), pl.col(\"low\"), pl.col(\"low_extremal_cand\"), pl.col(\"rolling_low\"))\n",
    ")\n",
    "pl.Config.set_tbl_rows(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Config.set_tbl_rows(-1)\n",
    "print(extremal_df\n",
    "      .filter(pl.col(\"date\").is_between(datetime.date(year=2023, month=11, day=29), datetime.date(year=2024, month=1, day=15)))\n",
    "      .select(pl.col(\"date\"), pl.col(\"high\"), pl.col(\"high_extremal_cand\"), pl.col(\"rolling_high\"), pl.col(\"low\"), pl.col(\"low_extremal_cand\"), pl.col(\"rolling_low\"))\n",
    ")\n",
    "pl.Config.set_tbl_rows(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_csv_path = stock.PROJECT_ROOT / \"data/data_j.csv\"\n",
    "code_df = pl.read_csv(code_csv_path)\n",
    "code_df = code_df.filter(pl.col(\"市場・商品区分\").str.contains(\"内国株式\"))\n",
    "code_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data_dir = stock.PROJECT_ROOT / \"data/daily\"\n",
    "\n",
    "def get_pivot_df(code: str) -> pl.DataFrame:\n",
    "    df = stock.kabutan.read_data_csv(daily_data_dir / f\"{code}.csv\")\n",
    "\n",
    "    df = df.with_columns(\n",
    "        co=(pl.col(\"close\") - pl.col(\"open\")),\n",
    "        hl=(pl.col(\"high\") - pl.col(\"low\")),\n",
    "        next_open=pl.col(\"open\").shift(-1),\n",
    "        next_co=((pl.col(\"close\") - pl.col(\"open\")) / pl.col(\"open\")).shift(-1),\n",
    "        prev_volume=pl.col(\"volume\").shift(1),\n",
    "        close_avg=pl.col(\"close\").rolling_mean(window_size=20), \n",
    "        hl_median=(pl.col(\"high\") - pl.col(\"low\")).rolling_median(window_size=20),\n",
    "        volume_avg=pl.col(\"volume\").rolling_mean(window_size=20),  # 直近1ヶ月の出来高の平均\n",
    "        volume_min=pl.col(\"volume\").rolling_min(window_size=20),  # 直近1ヶ月の出来高の最低\n",
    "    )\n",
    "    df = df.with_columns(\n",
    "        diff_co=pl.col(\"co\").diff(n=1),\n",
    "        diff_hl=pl.col(\"hl\").diff(n=1),\n",
    "        diff_high=pl.col(\"high\").diff(n=1),\n",
    "        diff_low=pl.col(\"low\").diff(n=1)\n",
    "    )\n",
    "    pivot_df = df.filter(\n",
    "        pl.col(\"next_open\").is_not_null()\n",
    "        & ((pl.col(\"diff_high\") < 0) & (pl.col(\"diff_low\") > 0)) # 前日の値幅に値動きが収まっている.\n",
    "        # & (pl.col(\"co\").abs() * 2 < pl.col(\"hl\"))  # 始値と終値がほぼ同じ\n",
    "        & (pl.col(\"hl\") < pl.col(\"hl_median\")) # 値動きが小さい\n",
    "        # & (pl.col(\"co\") < 0)  # 始値と終値がほぼ同じ\n",
    "        & (pl.col(\"close\") < pl.col(\"close_avg\"))  # 移動平均より株価が上\n",
    "        & (pl.col(\"volume\") - pl.col(\"volume_min\") * 1.05 < 0)  # 出来高が直近1ヶ月で最低に近い\n",
    "        & (pl.col(\"volume\") * 2 < pl.col(\"volume_avg\"))  # 出来高が1ヶ月の平均値より十分小さい\n",
    "        & (pl.col(\"prev_volume\") < pl.col(\"volume_avg\"))\n",
    "        & (pl.col(\"volume\")  > 1000)\n",
    "        #& (pl.col(\"low\") > pl.col(\"next_open\"))  # 次の日の始a値が前日の高値より高い\n",
    "        #& (pl.col(\"low\") * 0.95 < pl.col(\"next_open\"))\n",
    "    )\n",
    "    return pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "others = []\n",
    "for csv_path in daily_data_dir.glob(\"*.csv\"):\n",
    "    code = csv_path.stem\n",
    "    df = get_pivot_df(code)\n",
    "    if code in code_df[\"コード\"]:\n",
    "        dfs.append(df.with_columns(\n",
    "            code=pl.lit(code).cast(str)\n",
    "        ))\n",
    "    else:\n",
    "        others.append(df.with_columns(\n",
    "            code=pl.lit(code).cast(str)\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pl.concat(dfs)\n",
    "all_df = all_df.sort(pl.col(\"date\"))\n",
    "#df = all_df.filter(pl.col(\"low\") > pl.col(\"next_open\"))\n",
    "df = all_df.filter(pl.col(\"high\") < pl.col(\"next_open\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_up, num_down = (df[\"next_co\"] > 0).sum(), (df[\"next_co\"] < 0).sum()\n",
    "(df[\"next_co\"]).sum(), num_up / (num_up + num_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2014, 2025):\n",
    "    df_year = df.filter(pl.col(\"date\").is_between(datetime.date(year=year, month=1, day=1), datetime.date(year=year, month=12, day=31)))\n",
    "    #df_year.sort(pl.col(\"next_co\"))\n",
    "    print(\"year = {}, total return = {}\".format(year, df_year[\"next_co\"].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits = {}\n",
    "for i in range(len(df)):\n",
    "    date = df[\"date\"][i]\n",
    "    if date not in profits:\n",
    "        profits[date] = []\n",
    "    profits[date].append(df[\"next_co\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits_per_day = {key: sum(val) / len(val) for key, val in profits.items()}\n",
    "profits_per_year = {}\n",
    "for day, val in profits_per_day.items():\n",
    "    year = day.year\n",
    "    if year not in profits_per_year:\n",
    "        profits_per_year[year] = []\n",
    "    profits_per_year[year].append(val)\n",
    "profits_per_year = {key: sum(val) for key, val in profits_per_year.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2024\n",
    "df_year = df.filter(pl.col(\"date\").is_between(datetime.date(year=year, month=1, day=1), datetime.date(year=year, month=12, day=31)))\n",
    "pl.Config.set_tbl_rows(-1)\n",
    "print(df_year.select(pl.col(\"date\"), pl.col(\"next_co\"), pl.col(\"code\")))\n",
    "pl.Config.set_tbl_rows(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
