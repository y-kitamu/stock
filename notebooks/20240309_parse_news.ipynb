{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from pydantic import BaseModel, Field\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "login_url = \"https://account.kabutan.jp/login\"\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"detach\", True)\n",
    "driver = webdriver.Remote(\n",
    "    command_executor=\"http://localhost:4444/wd/hub\",\n",
    "    options=options\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "login_info = {\n",
    "    \"email\": \"ymyk6602@gmail.com\",\n",
    "    \"pass\": \"ymyk6422\"\n",
    "}\n",
    "driver.get(login_url)\n",
    "driver.find_element(By.ID, \"session_email\").send_keys(login_info[\"email\"])\n",
    "driver.find_element(By.ID, \"session_password\").send_keys(login_info[\"pass\"])\n",
    "\n",
    "for elem in driver.find_elements(By.TAG_NAME, \"input\"):\n",
    "    if elem.get_attribute(\"type\") == \"submit\" and elem.get_attribute(\"value\") == \"ログインする\":\n",
    "        elem.click()\n",
    "        break\n",
    "print(driver.current_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kabutan_url = \"https://kabutan.jp\"\n",
    "news_list_url_base = \"https://kabutan.jp/news/marketnews/?category=9&date={}\"\n",
    "stock_url_template = \"https://kabutan.jp/stock/kabuka?code={}&ashi=day&page={}\"\n",
    "\n",
    "def get_catalyst_news_url(date, driver=None):\n",
    "    news_list_url = news_list_url_base.format(date)\n",
    "    if driver is None:\n",
    "        html = requests.get(news_list_url).text\n",
    "    else:\n",
    "        driver.get(news_list_url)\n",
    "        html = driver.page_source\n",
    "\n",
    "    soup = BeautifulSoup(html)\n",
    "    for link in soup.find_all(\"a\"):\n",
    "        if \"【明日の好悪材料】を開示情報でチェック！\" in link.text and date in link[\"href\"]:\n",
    "            return kabutan_url + link[\"href\"]\n",
    "        \n",
    "def get_catalyst_stock_list(news_url, driver = None):\n",
    "    if driver is None:\n",
    "        res = requests.get(news_url)\n",
    "        html = res.text\n",
    "    else:\n",
    "        driver.get(news_url)\n",
    "        html = driver.page_source\n",
    "    soup = BeautifulSoup(html)\n",
    "\n",
    "    good_catalyst = \"【好材料】\"\n",
    "    bad_catalyst = \"【悪材料】\"\n",
    "    mid_catalyst = \"【好悪材料が混在】\"\n",
    "\n",
    "    regex = re.compile(\"■.*<(\\d*)>\")\n",
    "\n",
    "    catalyst_codes = {\n",
    "        \"good\" : [],\n",
    "        \"bad\" : [],\n",
    "        \"mid\" : []\n",
    "    }\n",
    "    current_key = \"\"\n",
    "    for line in soup.text.split(\"\\n\"):\n",
    "        if good_catalyst in line:\n",
    "            current_key = \"good\"\n",
    "        elif bad_catalyst in line:\n",
    "            current_key = \"bad\"\n",
    "        elif mid_catalyst in line:\n",
    "            current_key =\"mid\"\n",
    "            \n",
    "        match = regex.search(line)\n",
    "        if current_key in catalyst_codes and match is not None:\n",
    "            catalyst_codes[current_key].append(int(match.group(1)))\n",
    "    return catalyst_codes\n",
    "\n",
    "def search_stock_table_rows(soup, exclude_today = True):\n",
    "    res = []\n",
    "    for table in soup.find_all(\"table\"):\n",
    "        thead = table.find(\"tr\")\n",
    "        if thead is None:\n",
    "            continue\n",
    "        headers = [th.text for th in thead.find_all(\"th\")]\n",
    "        if len(headers) >= 4 and headers[1] == \"始値\" and headers[2] == \"高値\" and headers[3] == \"安値\" and headers[4] == \"終値\":\n",
    "            rows = table.find_all(\"tr\")[1:]\n",
    "            if len(rows) > (1 + int(exclude_today)):\n",
    "                res += rows \n",
    "    return res\n",
    "\n",
    "def get_values(base_url, start_page=0, max_page=1, driver=None):\n",
    "    results = {}\n",
    "    for i in range(start_page, max_page):\n",
    "        url = base_url.format(i + 1)\n",
    "        if driver is None:\n",
    "            html = requests.get(url).text\n",
    "        else:\n",
    "            driver.get(url)\n",
    "            html = driver.page_source\n",
    "        soup = BeautifulSoup(html)\n",
    "        rows = search_stock_table_rows(soup, i != 0)\n",
    "\n",
    "        if len(rows) == 0:\n",
    "            print(f\"stock table not found : {url}\")\n",
    "        \n",
    "        for row in rows:\n",
    "            cols = [col.text for col in row.findChildren(recursive=False)]\n",
    "            date = \"20{}{}{}\".format(*cols[0].split(\"/\"))\n",
    "            if cols[1] == \"－\":\n",
    "                continue\n",
    "            values = [float(val_str.replace(\",\", \"\")) for val_str in cols[1:5]]\n",
    "            results[date] = values\n",
    "        time.sleep(0.2)\n",
    "    return results\n",
    "\n",
    "def get_next_day_values(code, target_date: int | str, max_search_page=1, driver = None):\n",
    "    if isinstance(target_date, str):\n",
    "        target_date = int(target_date)\n",
    "    url = stock_url_template.format(code, \"{}\")\n",
    "    \n",
    "    for i in range(max_search_page, 0, -1):\n",
    "        stock_values = get_values(url, start_page=i - 1, max_page=i, driver=driver)\n",
    "        sorted_dates = sorted(stock_values.keys(), key=lambda x: int(x))\n",
    "        for idx, date in enumerate(sorted_dates):\n",
    "            if int(date) > target_date:\n",
    "                return i, date, stock_values[sorted_dates[idx - 1]], stock_values[date]\n",
    "    return None, None, None, None\n",
    "\n",
    "def calc_up_rate(values):\n",
    "    return (values[3] - values[0]) / values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatalystStock(BaseModel):\n",
    "    code: int\n",
    "    category: str\n",
    "    next_date: str = Field(default_factory=str)\n",
    "    target_date_values: list[float] = Field(default_factory=float)\n",
    "    next_date_values: list[float] = Field(default_factory=list)\n",
    "    up_rate: float = Field(default_factory=float)\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.up_rate = calc_up_rate(self.next_date_values)\n",
    "\n",
    "class CatalystStocks(BaseModel):\n",
    "    date: str = Field(default_factory=str)\n",
    "    stocks: list[CatalystStock] = Field(default_factory=list)\n",
    "\n",
    "def get_catalyst_stock_values(date, max_search_page, driver=None):\n",
    "    catalyst_news_url = get_catalyst_news_url(date, driver=driver)\n",
    "    if catalyst_news_url is None:\n",
    "        print(f\"Catalyst new not found : {date}\")\n",
    "        return None\n",
    "    \n",
    "    print(catalyst_news_url)\n",
    "    catalyst_codes = get_catalyst_stock_list(catalyst_news_url, driver=driver)\n",
    "    catalyst_stocks = CatalystStocks(date=date)\n",
    "\n",
    "    def to_datetime(date_str):\n",
    "        return datetime.datetime.strptime(str(date_str), \"%Y%m%d\")\n",
    "\n",
    "    for key, codes in catalyst_codes.items():\n",
    "        for code in codes:\n",
    "            max_page, next_date, target_date_values, next_date_values = get_next_day_values(\n",
    "                code, int(date), max_search_page=max_search_page)\n",
    "            \n",
    "            if next_date is None or to_datetime(next_date) - to_datetime(date) > datetime.timedelta(days=10):\n",
    "                print(f\"Failed to find next date value. code = {code}\")\n",
    "                continue\n",
    "            max_search_page = max_page\n",
    "            catalyst_stocks.stocks.append(\n",
    "                CatalystStock(code=code, category=key, next_date=next_date, \n",
    "                              target_date_values=target_date_values,\n",
    "                              next_date_values=next_date_values)\n",
    "            )\n",
    "    return catalyst_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.datetime(year=2022, month=12, day=20)\n",
    "end_date = datetime.datetime(year=2024, month=3, day=7)\n",
    "output_dir = Path(\"../data/catalyst\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "date = start_date\n",
    "while date != end_date:\n",
    "    date_str = date.strftime(\"%Y%m%d\")\n",
    "    print(f\"Start {date_str}\")\n",
    "    output_path = output_dir / (date_str + \".json\")\n",
    "\n",
    "    date += datetime.timedelta(days=1)\n",
    "    if output_path.exists():\n",
    "        print(f\"Skip : {date_str}\")\n",
    "        continue\n",
    "    \n",
    "    res = get_catalyst_stock_values(date_str, 10, driver=driver)\n",
    "    if res is not None:\n",
    "        with open(output_path, \"w\") as f:\n",
    "            f.write(res.model_dump_json(indent=4))\n",
    "        print(f\"Save to {output_path.as_posix()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
