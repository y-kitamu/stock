{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensortradeのtutorialをやってみる\n",
    "from tensortrade.oms.instruments import Instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USD = Instrument(\"USD\", 2, \"U.S. Dollar\")\n",
    "TTC = Instrument(\"TTC\", 8, \"Tensor Trade Coin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium.spaces import Discrete\n",
    "from tensortrade.env.default.actions import TensorTradeActionScheme\n",
    "from tensortrade.env.default.rewards import TensorTradeRewardScheme\n",
    "from tensortrade.env.generic import ActionScheme, TradingEnv, Renderer\n",
    "from tensortrade.core import Clock\n",
    "from tensortrade.feed.core import Stream, DataFeed\n",
    "from tensortrade.oms.instruments import ExchangePair\n",
    "from tensortrade.oms.wallets import Portfolio\n",
    "from tensortrade.oms.orders import Order, proportion_order, TradeSide, TradeType\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BSH(TensorTradeActionScheme):\n",
    "    registered_name = \"bsh\"\n",
    "\n",
    "    def __init__(self, cash: \"Wallet\", asset: \"Wallet\"):\n",
    "        super().__init__()\n",
    "        self.cash = cash\n",
    "        self.asset = asset\n",
    "\n",
    "        self.listeners = []\n",
    "        self.action = 0\n",
    "\n",
    "    @property\n",
    "    def action_space(self):\n",
    "        return Discrete(2)\n",
    "    \n",
    "    def attach(self, listener):\n",
    "        self.listeners += [listener]\n",
    "        return self\n",
    "    \n",
    "    def get_orders(self, action: int, portfolio: \"Portfolio\"):\n",
    "        order = None\n",
    "\n",
    "        if abs(action - self.action) > 0:\n",
    "            src = self.cash if self.action == 0 else self.asset\n",
    "            tgt = self.asset if self.action == 0 else self.cash\n",
    "            order = proportion_order(portfolio, src, tgt, 1.0)\n",
    "            self.action = action\n",
    "\n",
    "        for listener in self.listeners:\n",
    "            listener.on_action(action)\n",
    "\n",
    "        return [order]\n",
    "    \n",
    "    def reset(self):\n",
    "        super().reset()\n",
    "        self.action = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PBR(TensorTradeRewardScheme):\n",
    "    registered_name = \"pbr\"\n",
    "    \n",
    "    def __init__(self, price: \"Stream\"):\n",
    "        super().__init__()\n",
    "        self.position = -1\n",
    "\n",
    "        r = Stream.sensor(price, lambda p: p.value, dtype=\"float\").diff()\n",
    "        position = Stream.sensor(self, lambda rs: rs.position, dtype=\"float\")\n",
    "\n",
    "        reward = (r * position).fillna(0).rename(\"reward\")\n",
    "\n",
    "        self.feed = DataFeed([reward])\n",
    "        self.feed.compile()\n",
    "\n",
    "    def on_action(self, action: int):\n",
    "        self.position = -1 if action == 0 else 1\n",
    "\n",
    "    def get_reward(self, portfolio: \"Portfolio\"):\n",
    "        return self.feed.next()[\"reward\"]\n",
    "    \n",
    "    def reset(self):\n",
    "        self.position = -1\n",
    "        self.feed.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionChangeChart(Renderer):\n",
    "\n",
    "    def __init__(self, color: str = \"orange\"):\n",
    "        self.color = \"orange\"\n",
    "\n",
    "    def render(self, env, **kwargs):\n",
    "        history = pd.DataFrame(env.observer.renderer_history)\n",
    "\n",
    "        actions = list(history.action)\n",
    "        p = list(history.price)\n",
    "\n",
    "        buy = {}\n",
    "        sell = {}\n",
    "\n",
    "        for i in range(len(actions) - 1):\n",
    "            a1 = actions[i]\n",
    "            a2 = actions[i + 1]\n",
    "\n",
    "            if a1 != a2:\n",
    "                if a1 == 0 and a2 == 1:\n",
    "                    buy[i] = p[i]\n",
    "                else:\n",
    "                    sell[i] = p[i]\n",
    "\n",
    "        buy = pd.Series(buy)\n",
    "        sell = pd.Series(sell)\n",
    "\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "        fig.suptitle(\"Performance\")\n",
    "        axs[0].plot(np.arange(len(p)), p, label=\"price\", color=self.color)\n",
    "        axs[0].scatter(buy.index, buy.values, marker=\"^\", color=\"green\")\n",
    "        axs[0].scatter(sell.index, sell.values, marker=\"^\", color=\"red\")\n",
    "        axs[0].set_title(\"Trading Chart\")\n",
    "\n",
    "        performance_df = pd.DataFrame().from_dict(\n",
    "            env.action_scheme.portfolio.performance, orient=\"index\")\n",
    "        performance_df.plot(ax=axs[1])\n",
    "        axs[1].set_title(\"Net Worth\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import ray\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.registry import register_env, _global_registry\n",
    "\n",
    "import tensortrade.env.default as default\n",
    "from tensortrade.feed.core import DataFeed, Stream\n",
    "from tensortrade.oms.exchanges import Exchange\n",
    "from tensortrade.oms.services.execution.simulated import execute_order\n",
    "from tensortrade.oms.wallets import Wallet, Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_env(config):\n",
    "    x = np.arange(0, 2 * np.pi, 2 * np.pi / 1001)\n",
    "    y = 50 * np.sin(3 * x) + 100\n",
    "\n",
    "    # x = np.arange(0, 2 * np.pi, 2 * np.pi / 1000)\n",
    "    p = Stream.source(y, dtype=\"float\").rename(\"USD-TTC\")\n",
    "\n",
    "    bitfinex = Exchange(\"bitfinex\", service=execute_order)(p)\n",
    "\n",
    "    cash = Wallet(bitfinex, 100000 * USD)\n",
    "    asset = Wallet(bitfinex, 0 * TTC)\n",
    "    \n",
    "    portfolio = Portfolio(USD, [\n",
    "        cash, asset\n",
    "    ])\n",
    "\n",
    "    feed = DataFeed([\n",
    "        p,\n",
    "        p.rolling(window=10).mean().rename(\"fast\"),\n",
    "        p.rolling(window=50).mean().rename(\"medium\"),\n",
    "        p.rolling(window=100).mean().rename(\"slow\"),\n",
    "        p.log().diff().fillna(0).rename(\"lr\")\n",
    "    ])\n",
    "\n",
    "    reward_scheme = PBR(price=p)\n",
    "    action_scheme = BSH(cash=cash, asset=asset).attach(reward_scheme)\n",
    "    renderer_feed = DataFeed([\n",
    "        Stream.source(y, dtype=\"float\").rename(\"price\"),\n",
    "        Stream.sensor(action_scheme, lambda s: s.action, dtype=\"float\").rename(\"action\")\n",
    "    ])\n",
    "\n",
    "    environment = default.create(\n",
    "        feed=feed,\n",
    "        portfolio=portfolio,\n",
    "        action_scheme=action_scheme,\n",
    "        reward_scheme=reward_scheme,\n",
    "        renderer_feed=renderer_feed,\n",
    "        renderer=PositionChangeChart(),\n",
    "        window_size=config[\"window_size\"],\n",
    "        max_allowed_loss=0.6\n",
    "    )\n",
    "    return environment\n",
    "\n",
    "register_env(\"TradingEnv\", create_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PPOConfig().training(\n",
    "    gamma=0,\n",
    "    lr=8e-6,\n",
    "    vf_loss_coeff=0.5,\n",
    "    entropy_coeff=0.01,\n",
    "    lr_schedule=[\n",
    "        [0, 1e-1],\n",
    "        [int(1e2), 1e-2],\n",
    "        [int(1e3), 1e-3],\n",
    "        [int(1e4), 1e-4],\n",
    "        [int(1e5), 1e-5],\n",
    "        [int(1e6), 1e-6],\n",
    "        [int(1e7), 1e-7]\n",
    "    ],\n",
    "    lambda_=0.72,\n",
    ").environment(\n",
    "    env=\"TradingEnv\",\n",
    "    env_config={\n",
    "        \"window_size\": 25\n",
    "    },\n",
    "    clip_rewards=True,\n",
    ").framework(\n",
    "    framework=\"torch\",\n",
    ").debugging(\n",
    "    log_level=\"DEBUG\",\n",
    ").env_runners(\n",
    "    observation_filter=\"MeanStdFilter\",\n",
    "    # ignore_worker_failures=True,\n",
    "    num_env_runners=1,\n",
    ").resources(\n",
    "    num_gpus=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "    \"PPO\",\n",
    "    stop={\n",
    "        'env_runners/episode_reward_mean': 500\n",
    "    },\n",
    "    config=config.to_dict(),\n",
    "    checkpoint_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ray.rllib.algorithms.ppo as ppo\n",
    "#import ray.rllib.agents.ppo as ppo\n",
    "\n",
    "checkpoints = analysis.get_best_trial(\n",
    "    metric=\"env_runners/episode_reward_mean\",\n",
    "    mode=\"max\"\n",
    ").checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = config.build()\n",
    "algo.restore(checkpoints.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = create_env({\"window_size\": 25})\n",
    "\n",
    "episode_reward = 0\n",
    "done = False\n",
    "obs = env.reset()\n",
    "obs = obs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not done:\n",
    "    action = algo.compute_single_action(obs)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    episode_reward += reward\n",
    "    print(action, reward, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = config.build()\n",
    "for i in range(10):\n",
    "    result = algo.train()\n",
    "    result.pop(\"config\")\n",
    "    pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = create_env({\"window_size\": 25})\n",
    "\n",
    "episode_reward = 0\n",
    "done = False\n",
    "obs = env.reset()\n",
    "obs = obs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not done:\n",
    "    action = algo.compute_single_action(obs)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    episode_reward += reward\n",
    "    print(action, reward, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
