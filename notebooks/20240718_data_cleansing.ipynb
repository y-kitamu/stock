{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import datetime \n",
    "import random\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "\n",
    "import stock\n",
    "\n",
    "train_data_dir = stock.PROJECT_ROOT / \"data\" / \"train\"\n",
    "output_file_path = train_data_dir / \"{}.npz\".format(datetime.date.today().strftime(\"%Y%m%d\"))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eps、純利益から時価総額を計算する\n",
    "def calc_estimated_capitalization(code, current_date=datetime.date.today()):\n",
    "    fdf = stock.kabutan.read_financial_csv(code).filter(\n",
    "        (pl.col(\"duration\") == 3) & (pl.col(\"eps\").abs() > 1e-5)\n",
    "    ).sort(pl.col(\"annoounce_date\"))\n",
    "    df = stock.kabutan.read_data_csv(code, end_date=current_date).sort(pl.col(\"date\"))\n",
    "\n",
    "    if len(fdf) == 0:\n",
    "        return -1\n",
    "    num_stock = fdf[\"net_income\"][-1] * 1000000 / fdf[\"eps\"][-1]\n",
    "    est_capit = num_stock * df[\"close\"][-1]\n",
    "    return est_capit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# まずは学習データ準備\n",
    "target_data_dict = {}\n",
    "stacked = []\n",
    "codes = stock.kabutan.get_code_list()\n",
    "max_hold_days = 10\n",
    "\n",
    "for code in codes:\n",
    "    capt = calc_estimated_capitalization(code)\n",
    "    if capt > 100000000000: # 時価総額1000億円以上の場合はスキップ\n",
    "        continue\n",
    "    \n",
    "    df = stock.trend_template.calc_for_watch_list(code)\n",
    "    df = df.with_columns(\n",
    "        (pl.col(\"close\").rolling_max(window_size=max_hold_days).shift(-max_hold_days) / pl.col(\"open\").shift(-1)).alias(\"growing_rate\")\n",
    "    )\n",
    "    # df = df.with_columns(\n",
    "    #     ((pl.col(\"growing_rate\") - 1.0)* 100).log().alias(\"log_growing_rate\")\n",
    "    # )\n",
    "    # target_data_dict[code] = df\n",
    "    stacked.append(df.filter(pl.col(\"watch_list\")).with_columns(pl.lit(code).alias(\"code\")))\n",
    "\n",
    "stacked_df = pl.concat(stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainとvalidの分割日を決定する\n",
    "dates = stacked_df.sort(pl.col(\"date\"))[\"date\"]\n",
    "# この日付までをtrain、これより先をvalidationとする\n",
    "split_date = dates[int(len(dates) * 0.8)]\n",
    "\n",
    "train_df = stacked_df.filter(pl.col(\"date\") <= split_date)\n",
    "valid_df = stacked_df.filter(pl.col(\"date\") > split_date)\n",
    "print(\"Split date = {}, num train = {}, num_valid = {}\".format(split_date, len(train_df), len(valid_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv = stock.TRAIN_DATA_DIR / \"valid.csv\"\n",
    "valid_df.select(pl.col(\"date\"), pl.col(\"code\")).write_csv(output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_image(code, date, df, before_days):\n",
    "    output_dirname = \"\"\n",
    "    if df[\"growing_rate\"][before_days - 1] > 1.2:\n",
    "        output_dirname = \"pos\"\n",
    "    elif df[\"growing_rate\"][before_days - 1] > 1.1:\n",
    "        output_dirname = \"mid\"\n",
    "    else:\n",
    "        output_dirname = \"neg\"\n",
    "    output_path = Path(\"./tmp/{}/code{}_date{}_rate{:03d}.png\".format(\n",
    "        output_dirname, code, date.strftime(\"%Y%m%d\"), int((df[\"growing_rate\"][before_days - 1]) * 100)\n",
    "    ))\n",
    "    output_path.parent.mkdir(exist_ok=True)\n",
    "    if output_path.exists():\n",
    "        return\n",
    "\n",
    "    base = df[\"close\"][before_days - 1]\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.0, row_heights=[0.7, 0.3]\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Candlestick(\n",
    "            x=df[\"date\"],\n",
    "            open=df[\"open\"] / base,\n",
    "            high=df[\"high\"] / base,\n",
    "            low=df[\"low\"] / base,\n",
    "            close=df[\"close\"] / base,\n",
    "            name=\"candle\",\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "    # 売り買いポイント\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df[before_days][\"date\"],\n",
    "            y=df[before_days][\"open\"] / base,\n",
    "            mode=\"markers\",\n",
    "            name=\"buy\",\n",
    "            marker=dict(size=10, color=\"blue\"),\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "    # 売買高\n",
    "    fig.add_trace(go.Bar(x=df[\"date\"], y=df[\"volume\"], name=\"volume\"), row=2, col=1)\n",
    "    # グラフの設定\n",
    "    fig.update_layout(\n",
    "        xaxis_rangeslider_visible=False,\n",
    "        xaxis2_rangeslider_visible=False,\n",
    "        margin=go.layout.Margin(l=5, r=5, t=5, b=5, autoexpand=True),\n",
    "    )\n",
    "    fig.update_layout(hovermode=\"x unified\")\n",
    "    fig.update_layout(yaxis_range=[0.8, 1.6])\n",
    "    fig.update_traces(xaxis=\"x2\")\n",
    "    fig.update_xaxes(rangebreaks=[dict(bounds=[\"sat\", \"mon\"])])  # 土日を除外\n",
    "\n",
    "    fig.write_image(output_path)kkk\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データは直前x日分のcloseとvolumeにする\n",
    "def get_data_list(df, before_days = 30, after_days = 15):\n",
    "    outputs = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        code = df[\"code\"][i]\n",
    "        date = df[\"date\"][i]\n",
    "\n",
    "        target_df = stock.trend_template.calc_for_watch_list(code, start_date=date - datetime.timedelta(before_days * 2), end_date=date + datetime.timedelta(after_days * 2))\n",
    "        target_df = target_df.with_columns(\n",
    "            (pl.col(\"close\").rolling_max(window_size=max_hold_days).shift(-max_hold_days) / pl.col(\"open\").shift(-1)).alias(\"growing_rate\")\n",
    "        )\n",
    "        before_df = target_df.filter(pl.col(\"date\") <= date)\n",
    "        after_df = target_df.filter(pl.col(\"date\") > date)\n",
    "        if len(before_df) < before_days or len(after_df) < after_days:\n",
    "            continue\n",
    "            \n",
    "        out_df = before_df[-before_days:].vstack(after_df[:after_days])\n",
    "        outputs.append([code, date, out_df])\n",
    "        write_image(code, date, out_df, before_days)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_days = 30\n",
    "after_days = 15\n",
    "outputs = get_data_list(train_df, before_days=before_days, after_days=after_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_df = train_df.filter(pl.col(\"growing_rate\") > 1.4)\n",
    "outputs = get_data_list(good_df, before_days=before_days, after_days=after_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_data_dir = stock.TRAIN_DATA_DIR / \"neg\"\n",
    "file_list = [file for file in neg_data_dir.glob(\"*.png\")]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(file_list)\n",
    "target = []\n",
    "for file in file_list:\n",
    "    if int(file.stem.split(\"rate\")[1]) < 100:\n",
    "        target.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil\n",
    "\n",
    "selected = random.sample(target, 1000)\n",
    "output_dir = stock.TRAIN_DATA_DIR / \"neg_selected\"\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for d in selected:\n",
    "    shutil.copy(d, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poss = []\n",
    "negs = []\n",
    "\n",
    "xml_paths = [\n",
    "    stock.TRAIN_DATA_DIR / \"annotations_pos.xml\",\n",
    "    stock.TRAIN_DATA_DIR / \"annotations_neg.xml\"\n",
    "]\n",
    "\n",
    "for xml_path in xml_paths:\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    images = [child for child in root if child.tag == \"image\"]\n",
    "    for image in images:\n",
    "        for child in image:\n",
    "            if child.tag == \"tag\":\n",
    "                if child.attrib[\"label\"] == \"invalid base\":\n",
    "                    negs.append(image.attrib[\"name\"])\n",
    "                elif child.attrib[\"label\"] == \"proper base\":\n",
    "                    poss.append(image.attrib[\"name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(poss), len(negs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_list):\n",
    "    regex = re.compile(\"code(\\d+)_date(\\d+)_rate\\d+\")\n",
    "    datas = []\n",
    "    for data in data_list:\n",
    "        res = regex.search(data)\n",
    "        if res is None:\n",
    "            print(\"Regex not found : {}\".format(data))\n",
    "        code, date = res.group(1), datetime.datetime.strptime(res.group(2), \"%Y%m%d\").date()\n",
    "\n",
    "        df = stock.kabutan.read_data_csv(code, end_date=date)\n",
    "        if len(df) < 30:\n",
    "            print(\"Insufficient data length : {}, {}\", data, len(df))\n",
    "            continue\n",
    "\n",
    "        data = df[-30:].select(pl.col(\"open\"), pl.col(\"high\"), pl.col(\"low\"), pl.col(\"close\"), pl.col(\"volume\")).to_numpy()\n",
    "        data[:, :4] /= data[-1, 3]\n",
    "        data[:, 4] /= data[-1, 4]\n",
    "        \n",
    "        datas.append(data.reshape(-1))\n",
    "    return datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_data = np.array(get_data(poss))\n",
    "neg_data = np.array(get_data(negs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_true = np.array([int(re.search(\"rate(\\d+).png\", d).group(1)) for d in poss] + [int(re.search(\"rate(\\d+).png\", d).group(1)) for d in negs])\n",
    "#len(pos_data), len(neg_data)\n",
    "train_input = np.concatenate([pos_data, neg_data])\n",
    "np.savez(output_file_path, train_input, train_true, train_input, train_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
