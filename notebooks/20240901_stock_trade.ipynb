{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import gymnasium as gym\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.algorithms.algorithm import Algorithm\n",
    "import torch\n",
    "\n",
    "import stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feat_df(code: str, date: datetime.date, window_size: int = 30) -> pl.DataFrame | None:\n",
    "    # 日足データの読み込み\n",
    "    daily_df = stock.kabutan.read_data_csv(code)\n",
    "    # 分足データの読み込み\n",
    "    date_str = date.strftime(\"%Y%m%d\")\n",
    "    minutes_csv_path = stock.PROJECT_ROOT / f\"data/minutes/{date_str}\" /  f\"{code}_{date_str}.arrow\"\n",
    "    if not minutes_csv_path.exists():\n",
    "        return None\n",
    "    df = pl.read_ipc(minutes_csv_path)\n",
    "    df = df.filter(pl.col(\"datetime\").is_between(\n",
    "        datetime.datetime(date.year, date.month, date.day, 0, 0), datetime.datetime(date.year, date.month, date.day, 2, 30), closed=\"both\"\n",
    "    ) | pl.col(\"datetime\").is_between(\n",
    "        datetime.datetime(date.year, date.month, date.day, 3, 30), datetime.datetime(date.year, date.month, date.day, 6, 0), closed=\"both\"\n",
    "    )).sort(pl.col(\"datetime\"))\n",
    "\n",
    "    # 前日のデータを取得、正規化\n",
    "    prev_df = daily_df.filter(pl.col(\"date\") < df[\"datetime\"][0].date()).sort(pl.col(\"date\"))\n",
    "    if len(prev_df) == 0:\n",
    "        stock.logger.debug(\"No previous data\")\n",
    "        return None\n",
    "\n",
    "    prev_val = prev_df[\"close\"][-1]\n",
    "    mean_volume = prev_df.filter(pl.col(\"date\") > df[\"datetime\"][0].date() - datetime.timedelta(days=7))[\"volume\"].mean() / 302\n",
    "    feat_df = df.select(\n",
    "        pl.col(\"datetime\"),\n",
    "        pl.col(\"open\") / prev_val, \n",
    "        pl.col(\"high\") / prev_val,\n",
    "        pl.col(\"low\") / prev_val,\n",
    "        pl.col(\"close\") / prev_val,\n",
    "        pl.col(\"volume\") / mean_volume,\n",
    "    )\n",
    "\n",
    "    # 無いデータを埋める\n",
    "    dates = df[\"datetime\"].to_list()\n",
    "    date = dates[0].date()\n",
    "    cur_date = datetime.datetime(date.year, date.month, date.day, 0, 0)\n",
    "    add_dates = []\n",
    "    while cur_date <= datetime.datetime(date.year, date.month, date.day, 6, 0):\n",
    "        if cur_date not in dates :\n",
    "            if cur_date <= datetime.datetime(date.year, date.month, date.day, 2, 30) or datetime.datetime(date.year, date.month, date.day, 3, 30) <= cur_date:\n",
    "                #print(cur_date)\n",
    "                add_dates.append(cur_date)\n",
    "        cur_date += datetime.timedelta(minutes=1)\n",
    "        #cur_date += datetime.timedelta(minutes=1)\n",
    "    pad_df = pl.DataFrame(\n",
    "        {\n",
    "            \"datetime\": add_dates,\n",
    "            \"open\": [None] * len(add_dates),\n",
    "            \"high\": [None] * len(add_dates),\n",
    "            \"low\": [None] * len(add_dates),\n",
    "            \"close\": [None] * len(add_dates),\n",
    "            \"volume\": np.zeros(len(add_dates)),\n",
    "        }\n",
    "    )\n",
    "    feat_df = pl.concat([feat_df, pad_df]).sort(pl.col(\"datetime\"))\n",
    "    # 前にmargin_size (window_size - 1)分のdummyデータを追加\n",
    "    margin_df = pl.DataFrame(\n",
    "        {\n",
    "            \"datetime\": [datetime.datetime(date.year, date.month, date.day)] * (window_size - 1),\n",
    "            \"open\": np.ones(window_size - 1),\n",
    "            \"high\": np.ones(window_size - 1),\n",
    "            \"low\": np.ones(window_size - 1),\n",
    "            \"close\": np.ones(window_size - 1),\n",
    "            \"volume\": np.zeros(window_size - 1)\n",
    "        }\n",
    "    )\n",
    "    feat_df = pl.concat([margin_df, feat_df])\n",
    "    # nullを埋める\n",
    "    feat_df = feat_df.with_columns(\n",
    "        pl.col(\"close\").fill_null(strategy=\"forward\"),\n",
    "        pl.when(pl.col(\"volume\").is_null()).then(pl.lit(0)).otherwise(pl.col(\"volume\")).alias(\"volume\"),\n",
    "    ).with_columns(\n",
    "        pl.when(pl.col(\"open\").is_null()).then(pl.col(\"close\")).otherwise(pl.col(\"open\")).alias(\"open\"),\n",
    "        pl.when(pl.col(\"high\").is_null()).then(pl.col(\"close\")).otherwise(pl.col(\"high\")).alias(\"high\"),\n",
    "        pl.when(pl.col(\"low\").is_null()).then(pl.col(\"close\")).otherwise(pl.col(\"low\")).alias(\"low\"),\n",
    "    )    \n",
    "    feat_df = feat_df.select(pl.col(\"open\"), pl.col(\"high\"), pl.col(\"low\"), pl.col(\"close\"), pl.col(\"volume\"))\n",
    "\n",
    "    return feat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data (pl.DataFrame): 前処理済みのデータ (特徴量計算済み、欠損値処理済み)\n",
    "        window_size (int): 何日分のデータを取得するか\n",
    "    \"\"\"\n",
    "    def __init__(self, data_csvs: list[Path], window_size: int):\n",
    "        self.data_csvs = data_csvs\n",
    "        self.window_size = window_size\n",
    "        self.reset()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data) - self.window_size + 1\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> np.ndarray:\n",
    "        if 0 <= idx < len(self.data):\n",
    "            return self.data.slice(idx, self.window_size).to_numpy().flatten()\n",
    "        else:\n",
    "            raise IndexError\n",
    "        \n",
    "    def get_price(self, idx: int) -> float:\n",
    "        return self.data[\"close\"][idx + self.window_size - 1]\n",
    "    \n",
    "    def reset(self):\n",
    "        target_index = np.random.randint(len(self.data_csvs))\n",
    "        target_csv = self.data_csvs[target_index]\n",
    "        code = target_csv.stem.split(\"_\")[0]\n",
    "        date = datetime.datetime.strptime(target_csv.stem.split(\"_\")[1], \"%Y%m%d\").date()\n",
    "        self.data = create_feat_df(code, date, self.window_size)\n",
    "    \n",
    "    @property\n",
    "    def observation_space(self) -> gym.spaces.Space:\n",
    "        return gym.spaces.Box(\n",
    "            low=-np.inf,\n",
    "            high=np.inf,\n",
    "            shape=(int(self.window_size * len(self.data.columns)),),\n",
    "            dtype=np.float32,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingEnv(gym.Env):\n",
    "    \"\"\"前処理済み（特徴量計算済み）のpl.DataFrameを入力として、\n",
    "    step毎に状態を変化させ、報酬を返す環境クラス\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env_config):\n",
    "        super().__init__()\n",
    "        self.dataloader = env_config[\"dataloader\"]\n",
    "        self.current_index = 1\n",
    "        self.total_reward = 0\n",
    "        self.history = []\n",
    "\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "        self.observation_space = self.dataloader.observation_space\n",
    "    \n",
    "    def _calc_reward(self, action) -> float:\n",
    "        cur = self.dataloader.get_price(self.current_index)\n",
    "        pre = self.dataloader.get_price(self.current_index - 1)\n",
    "        action = 1 if action == 1 else -1\n",
    "        reward = (cur - pre) * action\n",
    "        return reward\n",
    "\n",
    "    def step(self, action)-> tuple[np.ndarray, float, bool, bool, dict[str, Any]]:\n",
    "        if self.current_index >= len(self.dataloader):\n",
    "            raise RuntimeError(\"Episode is done. Please reset the environment.\")\n",
    "        reward = self._calc_reward(action)\n",
    "        obs = self.dataloader[self.current_index]\n",
    "        self.current_index += 1\n",
    "        is_terminated = self.current_index >= len(self.dataloader)\n",
    "        is_truncated = False\n",
    "        info = {\n",
    "            \"index\": self.current_index - 1,\n",
    "            \"action\": action,\n",
    "            \"reward\": reward,\n",
    "            \"total_reward\": self.total_reward,\n",
    "            \"is_terminated\": is_terminated,\n",
    "            \"is_truncated\": is_truncated,\n",
    "        }\n",
    "        \n",
    "        self.total_reward += reward\n",
    "        self.history.append(info)\n",
    "\n",
    "        return obs, reward, is_terminated, is_truncated, info\n",
    "\n",
    "    def reset(self, *, seed: int | None = None, options: dict[str, Any] | None = None) -> tuple[np.ndarray, dict[str, Any]]:\n",
    "        self.current_index = 1\n",
    "        self.total_reward = 0\n",
    "        self.history = []\n",
    "        self.dataloader.reset()\n",
    "        return self.dataloader[0], {}\n",
    "\n",
    "    def render(self):\n",
    "        if len(self.history) == 0:\n",
    "            return\n",
    "        \n",
    "        df = pl.from_dicts(self.history)\n",
    "        df = df.with_columns(\n",
    "            pl.col(\"index\").map_elements(lambda s: self.dataloader.get_price(s), return_dtype=pl.Float64).alias(\"price\"),\n",
    "        )\n",
    "        \n",
    "        sellbuy_df = df.filter((pl.col(\"action\") != pl.col(\"action\").shift(1)).fill_null(True))\n",
    "        sell_df = sellbuy_df.filter(pl.col(\"action\") == 0)\n",
    "        buy_df = sellbuy_df.filter(pl.col(\"action\") == 1)\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 1, figsize=(10, 5))\n",
    "        axes.plot(df[\"index\"], df[\"price\"], label=\"price\")\n",
    "        axes.scatter(sell_df[\"index\"], sell_df[\"price\"], marker=\"^\", color=\"red\", label=\"sell\")\n",
    "        axes.scatter(buy_df[\"index\"], buy_df[\"price\"], marker=\"v\", color=\"green\", label=\"buy\")\n",
    "\n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 25\n",
    "csv_list = list((stock.PROJECT_ROOT / \"data/minutes_yf/\").rglob(\"1570*.arrow\"))\n",
    "# dataloader = DataLoader(csv_list, window_size=window_size)\n",
    "# len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(csv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = (\n",
    "    PPOConfig()\n",
    "    .api_stack(\n",
    "        enable_rl_module_and_learner=True,\n",
    "        enable_env_runner_and_connector_v2=True,    \n",
    "    ).learners(\n",
    "        num_learners=0,\n",
    "        num_gpus_per_learner=0,\n",
    "    ).training(\n",
    "        gamma=0,\n",
    "        lr_schedule=[\n",
    "            [0, 1e-1],\n",
    "            [int(1e2), 1e-2],\n",
    "            [int(1e3), 1e-3],\n",
    "            [int(1e4), 1e-4],\n",
    "            [int(1e5), 1e-5],\n",
    "            [int(1e6), 1e-6],\n",
    "            [int(1e7), 1e-7]\n",
    "        ],\n",
    "        lr=8e-6,\n",
    "        model={\"uses_new_env_runners\": True},\n",
    "        lambda_=0.72,\n",
    "        vf_loss_coeff=0.5,\n",
    "        entropy_coeff=0.01,\n",
    "    ).environment(\n",
    "        clip_rewards=True,\n",
    "        env=TradingEnv,\n",
    "        env_config={\"dataloader\": dataloader},\n",
    "    )\n",
    ")\n",
    "algo = config.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ray\n",
    "# from ray.rllib.algorithms import ppo\n",
    "#algo = ppo.PPO(env=TradingEnv, config={\"env_config\": {\"dataloader\": dataloader}})\n",
    "\n",
    "for i in range(30):\n",
    "    result = algo.train()\n",
    "    # if result[\"env_runners\"][\"episode_return_mean\"] > 0:\n",
    "    #     break\n",
    "    print(\"Episode reward mean: \", result[\"env_runners\"][\"episode_return_mean\"])\n",
    "\n",
    "checkpoint_dir = algo.save_to_path()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = Algorithm.from_checkpoint(checkpoint_dir)\n",
    "rl_module = algo.get_module()\n",
    "print(rl_module.input_specs_inference())\n",
    "\n",
    "env = TradingEnv({\"dataloader\": dataloader})\n",
    "obs, info = env.reset()\n",
    "while True:\n",
    "    input = torch.from_numpy(np.array([obs]))\n",
    "    action_logits = rl_module.forward_inference({\"obs\": input})[\"action_dist_inputs\"]\n",
    "    action = torch.argmax(action_logits[0]).numpy()\n",
    "    obs, reward, is_terminated, is_truncated, _ = env.step(action)\n",
    "    if is_terminated:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
