{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import random\n",
    "from typing import Any\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "from pydantic import BaseModel\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import gymnasium as gym\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.algorithms.algorithm import Algorithm\n",
    "import torch\n",
    "\n",
    "import stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data (pl.DataFrame): 前処理済みのデータ (特徴量計算済み、欠損値処理済み)\n",
    "        window_size (int): 何日分のデータを取得するか\n",
    "    \"\"\"\n",
    "    def __init__(self, code: str, start_date: datetime.datetime, end_date: datetime.datetime, episode_length: int, window_size: int, \n",
    "                 target_columns: list[str] = [\"open\", \"high\", \"low\", \"close\", \"volume\"]):\n",
    "        self.code = code\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.episode_length = episode_length\n",
    "        self.window_size = window_size\n",
    "        self.target_columns = target_columns\n",
    "        self.reset()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data) - self.window_size + 1\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> np.ndarray:\n",
    "        if 0 <= idx < len(self.data) - self.window_size + 1:\n",
    "            return self.data.slice(idx, self.window_size).select(*[pl.col(colname) for colname in self.target_columns]).to_numpy().flatten()\n",
    "        else:\n",
    "            raise IndexError\n",
    "        \n",
    "    def get_price(self, idx: int) -> float:\n",
    "        if 0 <= idx < len(self.data) - self.window_size + 1:\n",
    "            return self.data[\"close\"][idx + self.window_size - 1]\n",
    "        else:\n",
    "            raise IndexError\n",
    "    \n",
    "    def get_ohlcv(self, idx: int) -> np.ndarray:\n",
    "        if 0 <= idx < len(self.data) - self.window_size + 1:\n",
    "            return self.data.select(pl.col(\"open\"), pl.col(\"high\"), pl.col(\"low\"), pl.col(\"close\"), pl.col(\"volume\"))[idx + self.window_size - 1].to_numpy().flatten()\n",
    "        else:\n",
    "            raise IndexError\n",
    "    \n",
    "    def reset(self):\n",
    "        max_offset = int((self.end_date - self.start_date) / datetime.timedelta(minutes=1)) - self.window_size - self.episode_length\n",
    "        offset = random.randint(0, max_offset)\n",
    "        start_date = self.start_date + datetime.timedelta(minutes=offset)\n",
    "        end_date = start_date + datetime.timedelta(minutes=self.episode_length + self.window_size - 1)\n",
    "        self.data = stock.crypto.read_data(self.code, start_date, end_date)\n",
    "    \n",
    "    @property\n",
    "    def observation_space(self) -> gym.spaces.Space:\n",
    "        return gym.spaces.Box(\n",
    "            low=-np.inf,\n",
    "            high=np.inf,\n",
    "            shape=(int(self.window_size * len(self.target_columns)),),\n",
    "            dtype=np.float32,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action:\n",
    "    class ActionEnum(Enum):\n",
    "        BUY = 0\n",
    "        SELL = 1\n",
    "\n",
    "    def __init__(self, action):\n",
    "        self.action = Action.ActionEnum(action[\"action\"])\n",
    "        self.portion = action[\"portion\"]\n",
    "    \n",
    "\n",
    "class Portfolio:\n",
    "    \"\"\"cryptoのポートフォリオを表すクラス\n",
    "    \"\"\"\n",
    "    def __init__(self, initial_cash: float):\n",
    "        self.cash = initial_cash  # 現金\n",
    "        self.num_unit = 0  # 保有数量（取引単位）\n",
    "        self.acquision_price = 0  # 現在の保有株の取得価格（総額）\n",
    "        self.total = initial_cash  # 現在の総資産\n",
    "        self.prev_total = self.total\n",
    "\n",
    "        self.market_impact = 0.0001  # 取引時の市場インパクト\n",
    "        self.maker_fee = -0.0001  # メーカー手数料\n",
    "        self.taker_fee = 0.0005  # テイカー手数料\n",
    "\n",
    "        self.min_transaction_unit = 0.0001\n",
    "        self.max_transaction_unit = 5.0\n",
    "        self.max_loss_rate = 0.1\n",
    "\n",
    "        self.action_space = gym.spaces.Dict({\n",
    "            \"action\": gym.spaces.Discrete(2),\n",
    "            \"portion\": gym.spaces.Box(low=0.0, high=1.0, shape=(1,), dtype=np.float32),\n",
    "        })\n",
    "\n",
    "    def reset(self):\n",
    "        self.cash = self.total\n",
    "        self.num_unit = 0\n",
    "        self.acquision_price = 0\n",
    "        self.prev_total = self.total\n",
    "\n",
    "    def action(self, ohlcv: np.ndarray, action: Action):\n",
    "        if self.num_unit > 0:  # 保有株がある場合, loss cutの条件を満たしているか確認\n",
    "            loss_cut_price = (1 - self.max_loss_rate) * self.acquision_price / (self.num_unit * self.min_transaction_unit) \n",
    "            if loss_cut_price < ohlcv[2]:  # loss cutに引っかかったら売る\n",
    "                price = max(ohlcv[0], loss_cut_price)\n",
    "                self.sell(price, 1.0)\n",
    "                return\n",
    "            \n",
    "        if action.action == Action.ActionEnum.BUY:\n",
    "            self.buy(ohlcv[3], action.portion)\n",
    "        elif action.action == Action.ActionEnum.SELL:\n",
    "            self.sell(ohlcv[3], action.portion)\n",
    "\n",
    "        self.prev_total = self.total\n",
    "        self.total = self.cash + self.num_unit * self.min_transaction_unit * ohlcv[3]\n",
    "\n",
    "        return self.reward()\n",
    "\n",
    "    def reward(self):\n",
    "        return self.total - self.prev_total\n",
    "\n",
    "    def buy(self, price: float, portion: int):\n",
    "        price = price * (1 + self.market_impact + self.taker_fee)\n",
    "        units = math.floor(min(self.total * portion, self.cash) / (price * self.min_transaction_unit))\n",
    "        amount_price = price * self.min_transaction_unit * units\n",
    "        \n",
    "        self.cash -= amount_price\n",
    "        self.num_unit += units\n",
    "        self.acquision_price += amount_price\n",
    "\n",
    "    def sell(self, price: float, portion: int):\n",
    "        if self.num_unit == 0:\n",
    "            return\n",
    "        price = price * (1 - self.market_impact)\n",
    "        units = round(min(self.total * portion, self.num_unit * self.min_transaction_unit * price) / (price * self.min_transaction_unit))\n",
    "        amount_price = price * self.min_transaction_unit * units\n",
    "\n",
    "        self.cash += amount_price * (1.0 - self.maker_fee)\n",
    "        self.acquision_price *= (1.0 - units / self.num_unit)\n",
    "        self.num_unit -= units\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"cash: {self.cash}, num_unit: {self.num_unit}, total: {self.total}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingEnv(gym.Env):\n",
    "    \"\"\"前処理済み（特徴量計算済み）のpl.DataFrameを入力として、\n",
    "    step毎に状態を変化させ、報酬を返す環境クラス\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env_config):\n",
    "        super().__init__()\n",
    "        self.dataloader: DataLoader = env_config[\"dataloader\"]\n",
    "        self.portfolio: Portfolio = env_config[\"portfolio\"]\n",
    "        self.current_index = 1\n",
    "        self.total_reward = 0\n",
    "        self.history = []\n",
    "\n",
    "        self.action_space = self.portfolio.action_space\n",
    "        self.observation_space = self.dataloader.observation_space\n",
    "\n",
    "    #@stock.debug\n",
    "    def step(self, action)-> tuple[np.ndarray, float, bool, bool, dict[str, Any]]:\n",
    "        if self.current_index >= len(self.dataloader):\n",
    "            raise RuntimeError(\"Episode is done. Please reset the environment.\")\n",
    "        \n",
    "        reward = self.portfolio.action(self.dataloader.get_ohlcv(self.current_index), Action(action))\n",
    "        obs = self.dataloader[self.current_index]\n",
    "        self.current_index += 1\n",
    "        is_terminated = self.current_index >= len(self.dataloader)\n",
    "        is_truncated = False\n",
    "        info = {\n",
    "            \"index\": self.current_index - 1,\n",
    "            \"action\": action,\n",
    "            \"reward\": reward,\n",
    "            \"total_reward\": self.total_reward,\n",
    "            \"is_terminated\": is_terminated,\n",
    "            \"is_truncated\": is_truncated,\n",
    "        }\n",
    "        #breakpoint()\n",
    "        self.total_reward += reward\n",
    "        self.history.append(info)\n",
    "\n",
    "        return obs, reward, is_terminated, is_truncated, info\n",
    "\n",
    "    def reset(self, *, seed: int | None = None, options: dict[str, Any] | None = None) -> tuple[np.ndarray, dict[str, Any]]:\n",
    "        self.current_index = 1\n",
    "        self.total_reward = 0\n",
    "        self.history = []\n",
    "        self.dataloader.reset()\n",
    "        self.portfolio.reset()\n",
    "        return self.dataloader[0], {}\n",
    "\n",
    "    def render(self):\n",
    "        if len(self.history) == 0:\n",
    "            return\n",
    "        \n",
    "        df = pl.from_dicts(self.history)\n",
    "        df = df.with_columns(\n",
    "            pl.col(\"index\").map_elements(lambda s: self.dataloader.get_price(s), return_dtype=pl.Float64).alias(\"price\"),\n",
    "        )\n",
    "        \n",
    "        sellbuy_df = df.filter((pl.col(\"action\") != pl.col(\"action\").shift(1)).fill_null(True))\n",
    "        sell_df = sellbuy_df.filter(pl.col(\"action\") == 0)\n",
    "        buy_df = sellbuy_df.filter(pl.col(\"action\") == 1)\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 1, figsize=(10, 5))\n",
    "        axes.plot(df[\"index\"], df[\"price\"], label=\"price\")\n",
    "        axes.scatter(sell_df[\"index\"], sell_df[\"price\"], marker=\"^\", color=\"red\", label=\"sell\")\n",
    "        axes.scatter(buy_df[\"index\"], buy_df[\"price\"], marker=\"v\", color=\"green\", label=\"buy\")\n",
    "\n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\"BTC\", datetime.datetime(2022, 1, 1), datetime.datetime(2023, 1, 1), 1440, 25)\n",
    "portfolio = Portfolio(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = (\n",
    "    PPOConfig()\n",
    "    .api_stack(\n",
    "        enable_rl_module_and_learner=True,\n",
    "        enable_env_runner_and_connector_v2=True,    \n",
    "    ).learners(\n",
    "        num_learners=0,\n",
    "        num_gpus_per_learner=0,\n",
    "    ).training(\n",
    "        gamma=0,\n",
    "        lr_schedule=[\n",
    "            [0, 1e-1],\n",
    "            [int(1e2), 1e-2],\n",
    "            [int(1e3), 1e-3],\n",
    "            [int(1e4), 1e-4],\n",
    "            [int(1e5), 1e-5],\n",
    "            [int(1e6), 1e-6],\n",
    "            [int(1e7), 1e-7]\n",
    "        ],\n",
    "        lr=8e-6,\n",
    "        model={\"uses_new_env_runners\": True},\n",
    "        lambda_=0.72,\n",
    "        vf_loss_coeff=0.5,\n",
    "        entropy_coeff=0.01,\n",
    "    ).environment(\n",
    "        clip_rewards=True,\n",
    "        env=TradingEnv,\n",
    "        env_config={\n",
    "            \"dataloader\": dataloader,\n",
    "            \"portfolio\": portfolio,\n",
    "        },\n",
    "    )\n",
    ")\n",
    "algo = config.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ray\n",
    "# from ray.rllib.algorithms import ppo\n",
    "#algo = ppo.PPO(env=TradingEnv, config={\"env_config\": {\"dataloader\": dataloader}})\n",
    "\n",
    "for i in range(30):\n",
    "    #result = algo.train()\n",
    "    result = algo.train()\n",
    "    # if result[\"env_runners\"][\"episode_return_mean\"] > 0:\n",
    "    #     break\n",
    "    print(\"Episode reward mean: \", result[\"env_runners\"][\"episode_return_mean\"])\n",
    "\n",
    "checkpoint_dir = algo.save_to_path()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = Algorithm.from_checkpoint(checkpoint_dir)\n",
    "rl_module = algo.get_module()\n",
    "print(rl_module.input_specs_inference())\n",
    "\n",
    "env = TradingEnv({\"dataloader\": dataloader})\n",
    "obs, info = env.reset()\n",
    "while True:\n",
    "    input = torch.from_numpy(np.array([obs]))\n",
    "    action_logits = rl_module.forward_inference({\"obs\": input})[\"action_dist_inputs\"]\n",
    "    action = torch.argmax(action_logits[0]).numpy()\n",
    "    obs, reward, is_terminated, is_truncated, _ = env.step(action)\n",
    "    if is_terminated:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
